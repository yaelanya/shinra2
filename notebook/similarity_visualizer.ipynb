{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import json\n",
    "import pickle\n",
    "from wikipedia2vec import Wikipedia2Vec\n",
    "from gensim.models import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda x: [i for list_ in x for i in list_]\n",
    "\n",
    "def get_vectors(words, lang='ja'):\n",
    "    return np.array([w2v(w.lower(), lang=lang) for w in words])\n",
    "        \n",
    "def w2v(w, lang, embedding_dim=300):\n",
    "    try:\n",
    "        if lang == 'ja':\n",
    "            return ja_w2v.get_word_vector(w).tolist()\n",
    "        elif lang == 'en':\n",
    "            return transformer.predict([en_w2v.get_word_vector(w)])[0]\n",
    "        else:\n",
    "            print(\"Undefined language.\")\n",
    "            return [0.0] * embedding_dim\n",
    "    \n",
    "    except KeyError:\n",
    "        return [0.0] * embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "en_w2v = Wikipedia2Vec.load(\"../model/enwiki_20180420_300d.pkl\")\n",
    "ja_w2v = Wikipedia2Vec.load(\"../model/jawiki_20180420_300d.pkl\")\n",
    "\n",
    "with open(\"../model/wikipedia2vec_en2ja_mapping.pkl\", 'rb') as f:\n",
    "    transformer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data & vectorize\n",
    "methods_df = pd.read_pickle(\"../data/manufacturing_words_using_wikidata.pkl\")\n",
    "\n",
    "wiki_df = pd.read_csv(\"../data/train_split_words.csv\")\n",
    "wiki_df = wiki_df.append(pd.read_csv(\"../data/valid_split_words.csv\"))\n",
    "wiki_df._id = wiki_df._id.astype(str)\n",
    "\n",
    "wiki_df = \\\n",
    "wiki_df.assign(\n",
    "    wiki_wv = wiki_df.words.apply(lambda x: get_vectors(eval(x), lang='ja'))\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_word_vec = {}\n",
    "for _id, group in methods_df.groupby('_id'):\n",
    "    words = list(set(flatten(group.words.tolist())))\n",
    "    method_word_vec[str(_id)] = get_vectors(words, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CID</th>\n",
       "      <th>_id</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10686</td>\n",
       "      <td>2727000</td>\n",
       "      <td>hemimellitene is coal tar oil it isolated dist...</td>\n",
       "      <td>[hemimellitene, is, coal, tar, oil, it, isolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24434</td>\n",
       "      <td>433347</td>\n",
       "      <td>manufactured direct reaction potassium chlorid...</td>\n",
       "      <td>[manufactured, direct, reaction, potassium, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24434</td>\n",
       "      <td>433347</td>\n",
       "      <td>produced commercially united states based reac...</td>\n",
       "      <td>[produced, commercially, united, states, based...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24434</td>\n",
       "      <td>433347</td>\n",
       "      <td>israel implements reaction solvent extraction ...</td>\n",
       "      <td>[israel, implements, reaction, solvent, extrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24434</td>\n",
       "      <td>433347</td>\n",
       "      <td>17th 19th centuries bacterial nitrification ni...</td>\n",
       "      <td>[17th, 19th, centuries, bacterial, nitrificati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CID      _id                                      manufacturing  \\\n",
       "0  10686  2727000  hemimellitene is coal tar oil it isolated dist...   \n",
       "1  24434   433347  manufactured direct reaction potassium chlorid...   \n",
       "2  24434   433347  produced commercially united states based reac...   \n",
       "3  24434   433347  israel implements reaction solvent extraction ...   \n",
       "4  24434   433347  17th 19th centuries bacterial nitrification ni...   \n",
       "\n",
       "                                               words  \n",
       "0  [hemimellitene, is, coal, tar, oil, it, isolat...  \n",
       "1  [manufactured, direct, reaction, potassium, ch...  \n",
       "2  [produced, commercially, united, states, based...  \n",
       "3  [israel, implements, reaction, solvent, extrac...  \n",
       "4  [17th, 19th, centuries, bacterial, nitrificati...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = methods_df.groupby('_id').words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similarly(doc, kb):\n",
    "    return [_most_similarly(s, kb) for s in doc]\n",
    "\n",
    "def _most_similarly(s, kb):\n",
    "    mat_sim = scipy.spatial.distance.cdist(s, kb, 'cosine')\n",
    "    mat_sim[np.isnan(mat_sim)] = 1.0\n",
    "    most_sim = np.min(mat_sim, axis=1)\n",
    "    \n",
    "    return most_sim\n",
    "\n",
    "def visualizer(title, doc, labels, mat_sim, fp):\n",
    "    fp.write(\"<h2>{title}</h2><br>\\n\".format(**locals()))\n",
    "    for s, label, a_sim in zip(doc, labels, mat_sim):\n",
    "        for w, sim in zip(s, a_sim):\n",
    "            alpha = 1.0 - sim -0.5\n",
    "            if label:\n",
    "                fp.write(\"<b><span style=\\\"background-color: rgba(255,0,0,{alpha})\\\">{w}</span></b> \".format(**locals()))\n",
    "            else:\n",
    "                fp.write(\"<font color=gray><span style=\\\"background-color: rgba(255,0,0,{alpha})\\\">{w}</span></font> \".format(**locals()))\n",
    "        fp.write('<br>\\n')\n",
    "    fp.write('<br>\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"../dump/visualize2.html\", 'w', encoding='utf-8')\n",
    "\n",
    "for _id, group in wiki_df.groupby('_id'):\n",
    "    if method_word_vec.get(_id) is None:\n",
    "        p_wv = [[0.0] * 300]\n",
    "    else: \n",
    "        p_wv = method_word_vec.get(_id)\n",
    "    \n",
    "    doc = group.wiki_wv.values\n",
    "    raw_doc = group.words.apply(lambda x: eval(x)).values\n",
    "    title = group.title.values[0]\n",
    "    labels = group.label.values\n",
    "    mat_most_sim = most_similarly(doc, p_wv)\n",
    "    visualizer(title, raw_doc, labels, mat_most_sim, fp)\n",
    "    \n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
