{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [i for sub_l in l for i in sub_l]\n",
    "\n",
    "def true_positive(true, predict, partial=True):\n",
    "    if partial:\n",
    "        return partial_match(true, predict)\n",
    "    else:\n",
    "        return list(set(predict) & set(true))\n",
    "\n",
    "def false_positive(true, predict, partial=True):\n",
    "    if partial:\n",
    "        return list(set(predict) - set(partial_match(true, predict)))\n",
    "    else:\n",
    "        return list(set(predict) - set(true))\n",
    "\n",
    "def get_FP_dict(result: dict):\n",
    "    fp_dict = {}\n",
    "    for _id, entry in result.items():\n",
    "        fp_dict[_id] = {'title': entry['title'], 'data': false_positive(entry['true'], entry['predict'])}\n",
    "        \n",
    "    return fp_dict\n",
    "\n",
    "def get_TP_dict(result: dict):\n",
    "    tp_dict = {}\n",
    "    for _id, entry in result.items():\n",
    "        tp_dict[_id] = {'title': entry['title'], 'data': true_positive(entry['true'], entry['predict'])}\n",
    "        \n",
    "    return tp_dict\n",
    "\n",
    "def partial_match(true, pred):\n",
    "    # True data を返すか Predict data を返すか\n",
    "    return [t for t, p in itertools.product(true, pred) \\\n",
    "            if (re.search(fr'{re.escape(t)}', p) or re.search(fr'{re.escape(p)}', t))]\n",
    "\n",
    "def with_sents(predict_df, extracted_dict):\n",
    "    contain_sents_dict = {}\n",
    "    for _id, entry in predict_df.groupby('_id'):\n",
    "        contain_sent = [entry.apply(lambda x: x.repl_sentence if item in x.extracted else np.nan, axis=1).dropna().tolist() \n",
    "                        for item in extracted_dict[_id]['data']]\n",
    "        contain_sents_dict[_id] = {\n",
    "            'title': extracted_dict[_id]['title']\n",
    "            , 'data': [{'extracted': item, 'sentence': sents} for item, sents in zip(extracted_dict[_id]['data'], contain_sent)]\n",
    "        }\n",
    "    \n",
    "    return contain_sents_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>extracted</th>\n",
       "      <th>title</th>\n",
       "      <th>repl_words</th>\n",
       "      <th>repl_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10166</td>\n",
       "      <td>現在ではアンモニアの工業生産はハーバー・ボッシュ法によるものが一般的である。</td>\n",
       "      <td>[ハーバー・ボッシュ法]</td>\n",
       "      <td>アンモニア</td>\n",
       "      <td>[現在, で, は, [title-compound], の, 工業, 生産, は, ハーバ...</td>\n",
       "      <td>現在では[title-compound]の工業生産はハーバー・ボッシュ法によるものが一般的である。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _id                                sentence     extracted  title  \\\n",
       "0  10166  現在ではアンモニアの工業生産はハーバー・ボッシュ法によるものが一般的である。  [ハーバー・ボッシュ法]  アンモニア   \n",
       "\n",
       "                                          repl_words  \\\n",
       "0  [現在, で, は, [title-compound], の, 工業, 生産, は, ハーバ...   \n",
       "\n",
       "                                       repl_sentence  \n",
       "0  現在では[title-compound]の工業生産はハーバー・ボッシュ法によるものが一般的である。  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_pickle(\"../../data/test_IOB_repl_compound.pkl\")\n",
    "test_df = test_df[['_id', 'title', 'sentence', 'repl_words']]\n",
    "test_df['repl_sentence'] = test_df.repl_words.apply(lambda x: ''.join(x))\n",
    "\n",
    "train_df = pd.read_pickle(\"../../data/train_IOB_repl_compound.pkl\")\n",
    "train_df = train_df.loc[:, ['_id', 'title', 'sentence', 'repl_words']]\n",
    "train_production_df = pd.read_pickle(\"../../dump/train_production_with_extracted.pkl\")\n",
    "train_production_df = pd.merge(train_production_df, train_df, on=['_id', 'sentence'])\n",
    "train_production_df['repl_sentence'] = train_production_df.repl_words.apply(lambda x: ''.join(x))\n",
    "train_production_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_production_df = pd.merge(\n",
    "    pd.read_pickle(\"../../dump/pred_production_with_tag_seq.pkl\")\n",
    "    , test_df\n",
    "    , on=['_id', 'sentence']\n",
    ")\n",
    "predict_production_repl_df = pd.merge(\n",
    "    pd.read_pickle(\"../../dump/pred_production_using_compound-list_with_tag_seq.pkl\")\n",
    "    , test_df\n",
    "    , on=['_id', 'sentence']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../output/result/production.json\", 'r') as f:\n",
    "    result_production = json.load(f)\n",
    "    \n",
    "with open(\"../../output/result/production_using_compound-list.json\", 'r') as f:\n",
    "    result_production_repl = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_fp_dict = get_FP_dict(result_production)\n",
    "production_repl_fp_dict = get_FP_dict(result_production_repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_tp_dict = get_TP_dict(result_production)\n",
    "production_repl_tp_dict = get_TP_dict(result_production_repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_TP_diff = {}\n",
    "for _id, entry in result_production.items():\n",
    "    production_TP_diff[_id] = {\n",
    "        'title': entry['title']\n",
    "        , 'data': list(set(production_repl_tp_dict[_id]['data']) - set(production_tp_dict[_id]['data']))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../output/error_analysis/production_TP_add.json\", 'w') as f:\n",
    "    json.dump(production_TP_diff, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_sent_df = pd.DataFrame()\n",
    "for _id, entry in with_sents(predict_production_repl_df, production_repl_fp_dict).items():\n",
    "    sents = list(set(flatten([extraction['sentence'] for extraction in entry['data']])))\n",
    "    if not sents:\n",
    "        continue\n",
    "    fp_sent_df = fp_sent_df.append(pd.DataFrame({'title': entry['title'], 'sentence': sents}))\n",
    "    \n",
    "tp_sent_df = pd.DataFrame()\n",
    "for _id, entry in with_sents(predict_production_repl_df, production_repl_tp_dict).items():\n",
    "    sents = list(set(flatten([extraction['sentence'] for extraction in entry['data']])))\n",
    "    if not sents:\n",
    "        continue\n",
    "    tp_sent_df = tp_sent_df.append(pd.DataFrame({'title': entry['title'], 'sentence': sents}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df = pd.merge(tp_sent_df, fp_sent_df, on='sentence', how='right')\n",
    "sent_df = sent_df[sent_df.title_x.isna()]\n",
    "sent_df = sent_df.drop(columns='title_x').rename(columns={'title_y': 'title'})[['title', 'sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df.to_csv(\"../../output/error_analysis/production_diff_add_sentence.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_sent_df = pd.DataFrame()\n",
    "for _id, entry in with_sents(predict_production_df, production_tp_dict).items():\n",
    "    sents = list(set(flatten([extraction['sentence'] for extraction in entry['data']])))\n",
    "    if not sents:\n",
    "        continue\n",
    "    tp_sent_df = tp_sent_df.append(pd.DataFrame({'title': entry['title'], 'sentence': sents}))\n",
    "    \n",
    "repl_tp_sent_df = pd.DataFrame()\n",
    "for _id, entry in with_sents(predict_production_repl_df, production_repl_tp_dict).items():\n",
    "    sents = list(set(flatten([extraction['sentence'] for extraction in entry['data']])))\n",
    "    if not sents:\n",
    "        continue\n",
    "    repl_tp_sent_df = repl_tp_sent_df.append(pd.DataFrame({'title': entry['title'], 'sentence': sents}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df = pd.merge(tp_sent_df, repl_tp_sent_df, on='sentence', how='right')\n",
    "sent_df = sent_df[sent_df.title_x.isna()]\n",
    "sent_df = sent_df.drop(columns='title_x').rename(columns={'title_y': 'title'})[['title', 'sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df.to_csv(\"../../output/error_analysis/production_diff_add_TP_sentence.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop\n",
    "#merge_df = pd.merge(predict_production_df, predict_production_repl_df, on=['_id', 'repl_sentence'], how='left')\n",
    "# Add\n",
    "merge_df = pd.merge(predict_production_repl_df, predict_production_df, on=['_id', 'repl_sentence'], how='left')\n",
    "merge_df = merge_df[merge_df.sentence_y.isna()]\n",
    "merge_df = merge_df[['_id', 'title_x', 'repl_sentence', 'extracted_x']].rename(columns={'title_x': 'title', 'extracted_x': 'extracted'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "patt = r'合成|製造|製法|反応|生成|得(る|られる)' # サブタイトルからそれっぽいのを取った"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/var/pyenv/versions/3.6.1/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(len(merge_df))\n",
    "print(len(merge_df[merge_df.repl_sentence.str.contains(patt)].repl_sentence.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.to_csv(\"../../output/error_analysis/production_diff_add_sentence.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングデータから アノテーション-文 の対応付データを作成\n",
    "contain_sents_dict = {}\n",
    "for _id, entry in train_production_df.groupby('_id'):\n",
    "    productions = list(set(entry.extracted.values.sum()))\n",
    "    contain_sent = [entry.apply(lambda x: x.repl_sentence if prod in x.extracted else np.nan, axis=1).dropna().tolist() for prod in productions]\n",
    "    contain_sents_dict[_id] = {\n",
    "        'title': entry.title.tolist()[0]\n",
    "        , 'data': [{'extracted': prod, 'sentence': sents} for prod, sents in zip(productions, contain_sent)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520\n",
      "198\n"
     ]
    }
   ],
   "source": [
    "print(len(train_production_df))\n",
    "print(train_production_df.repl_words.apply(lambda x: \"[title-compound]\" in x).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
