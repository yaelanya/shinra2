{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [i for sub_l in l for i in sub_l]\n",
    "\n",
    "def true_positive(true, predict):\n",
    "    return list(set(predict) & set(true))\n",
    "\n",
    "def false_positive(true, predict):\n",
    "    return list(set(predict) - set(true))\n",
    "\n",
    "def get_FP_dict(result: dict):\n",
    "    fp_dict = {}\n",
    "    for _id, entry in result.items():\n",
    "        fp_dict[_id] = {'title': entry['title'], 'data': false_positive(entry['true'], entry['predict'])}\n",
    "        \n",
    "    return fp_dict\n",
    "\n",
    "def get_TP_dict(result: dict):\n",
    "    tp_dict = {}\n",
    "    for _id, entry in result.items():\n",
    "        tp_dict[_id] = {'title': entry['title'], 'data': true_positive(entry['true'], entry['predict'])}\n",
    "        \n",
    "    return tp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/compound_train.json\", 'r') as f:\n",
    "    title_dict = {str(entry['WikipediaID']): entry['Name'] for entry in json.load(f)['entry']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>extracted</th>\n",
       "      <th>title</th>\n",
       "      <th>repl_words</th>\n",
       "      <th>repl_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10166</td>\n",
       "      <td>水に良く溶けるため、水溶液（アンモニア水）として使用されることも多く、化学工業では基礎的な窒...</td>\n",
       "      <td>[窒素]</td>\n",
       "      <td>アンモニア</td>\n",
       "      <td>[水, に, 良く, 溶ける, ため, 、, 水溶液, （, [compound], ）, ...</td>\n",
       "      <td>水に良く溶けるため、水溶液（[compound]）として使用されることも多く、化学工業では基...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10166</td>\n",
       "      <td>窒素原子上の孤立電子対のはたらきにより、金属錯体の配位子となり、その場合はアンミンと呼ばれる。</td>\n",
       "      <td>[窒素]</td>\n",
       "      <td>アンモニア</td>\n",
       "      <td>[窒素, 原子, 上, の, 孤立, 電子, 対, の, はたらき, により, 、, 金属,...</td>\n",
       "      <td>窒素原子上の孤立電子対のはたらきにより、金属錯体の配位子となり、その場合はアンミンと呼ばれる。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10166</td>\n",
       "      <td>アモンの塩が意味する化合物は食塩と尿から合成されていた塩化アンモニウムである。</td>\n",
       "      <td>[塩化アンモニウム]</td>\n",
       "      <td>アンモニア</td>\n",
       "      <td>[アモン, の, 塩, が, 意味, する, 化合, 物, は, [compound], と...</td>\n",
       "      <td>アモンの塩が意味する化合物は[compound]と尿から合成されていた[compound]である。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10166</td>\n",
       "      <td>アンモニア分子は窒素を中心とする四面体構造を取っており、各頂点には3つの水素原子と一対の孤立...</td>\n",
       "      <td>[窒素, 水素]</td>\n",
       "      <td>アンモニア</td>\n",
       "      <td>[[title-compound], 分子, は, 窒素, を, 中心, と, する, 四,...</td>\n",
       "      <td>[title-compound]分子は窒素を中心とする四面体構造を取っており、各頂点には3つ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10166</td>\n",
       "      <td>塩化水素（塩酸）を近づけると塩化アンモニウム (NH4Cl) の白煙を生じる。</td>\n",
       "      <td>[塩化アンモニウム]</td>\n",
       "      <td>アンモニア</td>\n",
       "      <td>[[compound], （, [compound], ）, を, 近づける, と, [co...</td>\n",
       "      <td>[compound]（[compound]）を近づけると[compound]([compou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _id                                           sentence   extracted  \\\n",
       "0  10166  水に良く溶けるため、水溶液（アンモニア水）として使用されることも多く、化学工業では基礎的な窒...        [窒素]   \n",
       "1  10166    窒素原子上の孤立電子対のはたらきにより、金属錯体の配位子となり、その場合はアンミンと呼ばれる。        [窒素]   \n",
       "2  10166            アモンの塩が意味する化合物は食塩と尿から合成されていた塩化アンモニウムである。  [塩化アンモニウム]   \n",
       "3  10166  アンモニア分子は窒素を中心とする四面体構造を取っており、各頂点には3つの水素原子と一対の孤立...    [窒素, 水素]   \n",
       "4  10166            塩化水素（塩酸）を近づけると塩化アンモニウム (NH4Cl) の白煙を生じる。  [塩化アンモニウム]   \n",
       "\n",
       "   title                                         repl_words  \\\n",
       "0  アンモニア  [水, に, 良く, 溶ける, ため, 、, 水溶液, （, [compound], ）, ...   \n",
       "1  アンモニア  [窒素, 原子, 上, の, 孤立, 電子, 対, の, はたらき, により, 、, 金属,...   \n",
       "2  アンモニア  [アモン, の, 塩, が, 意味, する, 化合, 物, は, [compound], と...   \n",
       "3  アンモニア  [[title-compound], 分子, は, 窒素, を, 中心, と, する, 四,...   \n",
       "4  アンモニア  [[compound], （, [compound], ）, を, 近づける, と, [co...   \n",
       "\n",
       "                                       repl_sentence  \n",
       "0  水に良く溶けるため、水溶液（[compound]）として使用されることも多く、化学工業では基...  \n",
       "1    窒素原子上の孤立電子対のはたらきにより、金属錯体の配位子となり、その場合はアンミンと呼ばれる。  \n",
       "2  アモンの塩が意味する化合物は[compound]と尿から合成されていた[compound]である。  \n",
       "3  [title-compound]分子は窒素を中心とする四面体構造を取っており、各頂点には3つ...  \n",
       "4  [compound]（[compound]）を近づけると[compound]([compou...  "
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_pickle(\"../../data/train_IOB_repl_compound.pkl\")\n",
    "train_df = train_df.loc[:, ['_id', 'title', 'sentence', 'repl_words']]\n",
    "\n",
    "train_material_df = pd.read_pickle(\"../../dump/train_raw-material_with_extracted.pkl\")\n",
    "train_material_df = pd.merge(train_material_df, train_df, on=['_id', 'sentence'])\n",
    "train_material_df['repl_sentence'] = train_material_df.repl_words.apply(lambda x: ''.join(x))\n",
    "train_material_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle(\"../../data/test_IOB_repl_compound.pkl\")\n",
    "test_df = test_df[['_id', 'title', 'sentence', 'repl_words']]\n",
    "test_df['repl_sentence'] = test_df.repl_words.apply(lambda x: ''.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_material_df = pd.merge(\n",
    "    pd.read_pickle(\"../../dump/pred_raw-material_with_tag_seq.pkl\")\n",
    "    , test_df\n",
    "    , on=['_id', 'sentence']\n",
    ")\n",
    "predict_material_repl_df = pd.merge(\n",
    "    pd.read_pickle(\"../../dump/pred_raw-material_using_compound-list_with_tag_seq.pkl\")\n",
    "    , test_df\n",
    "    , on=['_id', 'sentence']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../output/result/raw-material.json\", 'r') as f:\n",
    "    result_materials = json.load(f)\n",
    "    \n",
    "with open(\"../../output/result/raw-material_using_compound-list.json\", 'r') as f:\n",
    "    result_materials_repl = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "materials_fp_dict = get_FP_dict(result_materials)\n",
    "materials_repl_fp_dict = get_FP_dict(result_materials_repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../output/error_analysis/raw-material_FP.json\", 'w') as f:\n",
    "    json.dump(materials_fp_dict, f)\n",
    "    \n",
    "with open(\"../../output/error_analysis/raw-material_using_compound-list_FP.json\", 'w') as f:\n",
    "    json.dump(materials_repl_fp_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "materials_tp_dict = get_TP_dict(result_materials)\n",
    "materials_repl_tp_dict = get_TP_dict(result_materials_repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../output/error_analysis/raw-material_TP.json\", 'w') as f:\n",
    "    json.dump(materials_tp_dict, f)\n",
    "    \n",
    "with open(\"../../output/error_analysis/raw-material_using_compound-list_TP.json\", 'w') as f:\n",
    "    json.dump(materials_repl_tp_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "materials_FP_diff = {}\n",
    "for _id, entry in result_materials.items():\n",
    "    materials_FP_diff[_id] = {\n",
    "        'title': entry['title']\n",
    "        , 'data': list(set(materials_fp_dict[_id]['data']) - set(materials_repl_fp_dict[_id]['data']))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../output/error_analysis/raw-material_FP_diff.json\", 'w') as f:\n",
    "    json.dump(materials_FP_diff, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "materials_TP_diff = {}\n",
    "for _id, entry in result_materials.items():\n",
    "    materials_TP_diff[_id] = {\n",
    "        'title': entry['title']\n",
    "        , 'data': list(set(materials_repl_tp_dict[_id]['data']) - set(materials_tp_dict[_id]['data']))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../output/error_analysis/raw-material_TP_diff.json\", 'w') as f:\n",
    "    json.dump(materials_TP_diff, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop\n",
    "#merge_df = pd.merge(predict_material_df, predict_material_repl_df, on=['_id', 'repl_sentence'], how='left')\n",
    "# Add\n",
    "merge_df = pd.merge(predict_material_repl_df, predict_material_df, on=['_id', 'repl_sentence'], how='left')\n",
    "merge_df = merge_df[merge_df.sentence_y.isna()]\n",
    "merge_df = merge_df[['_id', 'title_x', 'repl_sentence', 'extracted_x']].rename(\n",
    "    columns={'title_x': 'title', 'extracted_x': 'extracted'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "patt = r'合成|製造|製法|反応|生成|得(る|られる)' # サブタイトルからそれっぽいのを取った"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/var/pyenv/versions/3.6.1/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(len(merge_df))\n",
    "print(len(merge_df[merge_df.repl_sentence.str.contains(patt)].repl_sentence.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merge_df.groupby('_id').extracted.apply(lambda x: list(set(x.sum()))).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.to_csv(\"../../output/error_analysis/raw-material_diff_add_sentence.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_sents(predict_df, extracted_dict):\n",
    "    contain_sents_dict = {}\n",
    "    for _id, entry in predict_df.groupby('_id'):\n",
    "        contain_sent = [entry.apply(lambda x: x.repl_sentence if item in x.extracted else np.nan, axis=1).dropna().tolist() \n",
    "                        for item in extracted_dict[_id]['data']]\n",
    "        contain_sents_dict[_id] = {\n",
    "            'title': extracted_dict[_id]['title']\n",
    "            , 'data': [{'extracted': item, 'sentence': sents} for item, sents in zip(extracted_dict[_id]['data'], contain_sent)]\n",
    "        }\n",
    "    \n",
    "    return contain_sents_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_sent_df = pd.DataFrame()\n",
    "for _id, entry in with_sents(predict_material_repl_df, materials_repl_fp_dict).items():\n",
    "    sents = list(set(flatten([extraction['sentence'] for extraction in entry['data']])))\n",
    "    if not sents:\n",
    "        continue\n",
    "    fp_sent_df = fp_sent_df.append(pd.DataFrame({'title': entry['title'], 'sentence': sents}))\n",
    "    \n",
    "tp_sent_df = pd.DataFrame()\n",
    "for _id, entry in with_sents(predict_material_repl_df, materials_repl_tp_dict).items():\n",
    "    sents = list(set(flatten([extraction['sentence'] for extraction in entry['data']])))\n",
    "    if not sents:\n",
    "        continue\n",
    "    tp_sent_df = tp_sent_df.append(pd.DataFrame({'title': entry['title'], 'sentence': sents}))\n",
    "    \n",
    "sent_df = pd.merge(tp_sent_df, fp_sent_df, on='sentence', how='right')\n",
    "sent_df = sent_df[sent_df.title_x.isna()]\n",
    "sent_df = sent_df.drop(columns='title_x').rename(columns={'title_y': 'title'})[['title', 'sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df.to_csv(\"../../output/error_analysis/raw-material_using_compound-list_FP_sentence.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/var/pyenv/versions/3.6.1/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(len(sent_df))\n",
    "print(len(sent_df[sent_df.sentence.str.contains(patt)].sentence.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff をとっていないデータから作成\n",
    "contain_sents_dict = {}\n",
    "for _id, entry in predict_material_df.groupby('_id'):\n",
    "    contain_sent = [entry.apply(lambda x: x.repl_sentence if material in x.extracted else np.nan, axis=1).dropna().tolist() \n",
    "                    for material in materials_fp_dict[_id]['data']]\n",
    "    contain_sents_dict[_id] = {\n",
    "        'title': materials_fp_dict[_id]['title']\n",
    "        , 'data': [{'extracted': material, 'sentence': sents} for material, sents in zip(materials_fp_dict[_id]['data'], contain_sent)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff を取ったデータから作成\n",
    "contain_sents_dict = {}\n",
    "for _id, entry in predict_material_df.groupby('_id'):\n",
    "    contain_sent = [entry.apply(lambda x: x.repl_sentence if material in x.extracted else np.nan, axis=1).dropna().tolist() \n",
    "                    for material in materials_FP_diff[_id]['data']]\n",
    "    contain_sents_dict[_id] = {\n",
    "        'title': materials_FP_diff[_id]['title']\n",
    "        , 'data': [{'extracted': material, 'sentence': sents} for material, sents in zip(materials_FP_diff[_id]['data'], contain_sent)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングデータから アノテーション-文 の対応付データを作成\n",
    "contain_sents_dict = {}\n",
    "for _id, entry in train_material_df.groupby('_id'):\n",
    "    materials = list(set(entry.extracted.values.sum()))\n",
    "    contain_sent = [entry.apply(lambda x: x.repl_sentence if material in x.extracted else np.nan, axis=1).dropna().tolist() for material in materials]\n",
    "    contain_sents_dict[_id] = {\n",
    "        'title': entry.title.tolist()[0]\n",
    "        , 'data': [{'extracted': material, 'sentence': sents} for material, sents in zip(materials, contain_sent)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106\n",
      "444\n"
     ]
    }
   ],
   "source": [
    "print(len(train_material_df))\n",
    "print(train_material_df.repl_words.apply(lambda x: \"[title-compound]\" in x).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../output/error_analysis/raw-material_FP_diff_with_repl_sentence.json\", 'w') as f:\n",
    "    json.dump(contain_sents_dict, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flatten([v['data'] for v in contain_sents_dict.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
