{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda, Dense, Embedding, TimeDistributed, Bidirectional, LSTM, merge, concatenate, Dropout\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import metrics\n",
    "from gensim.models.poincare import PoincareModel\n",
    "from wikipedia2vec import Wikipedia2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix ramdom seed.\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train rows: 7435\n",
      "True: 508 \tFalse: 6927\n",
      "Number of validete rows: 1564\n",
      "True: 88 \tFalse: 1476\n"
     ]
    }
   ],
   "source": [
    "# load Production sentence data\n",
    "train_df = pd.read_csv(\"../data/train_split_words.csv\", dtype={'_id': str})\n",
    "valid_df = pd.read_csv(\"../data/valid_split_words.csv\", dtype={'_id': str})\n",
    "\n",
    "print(\"Number of train rows:\", len(train_df))\n",
    "print(\"True:\", len(train_df[train_df.label == True]), \"\\tFalse:\", len(train_df[train_df.label == False]))\n",
    "\n",
    "print(\"Number of validete rows:\", len(valid_df))\n",
    "print(\"True:\", len(valid_df[valid_df.label == True]), \"\\tFalse:\", len(valid_df[valid_df.label == False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/pageid2ChEBI.json\", 'r') as f:\n",
    "    pageid2ChEBI_table = json.load(f)\n",
    "\n",
    "ChEBI_df = pd.DataFrame()\n",
    "for _id, ChEBIs in pageid2ChEBI_table.items():\n",
    "    new_df = pd.DataFrame({'_id': [_id] * len(ChEBIs), 'ChEBI': ChEBIs})\n",
    "    ChEBI_df = ChEBI_df.append(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train rows: 8672\n",
      "True: 605 \tFalse: 8067\n",
      "Number of validete rows: 1918\n",
      "True: 103 \tFalse: 1815\n"
     ]
    }
   ],
   "source": [
    "# merge ChEBI DataFrame\n",
    "train_df = pd.merge(train_df, ChEBI_df, on='_id', how='left')\n",
    "valid_df = pd.merge(valid_df, ChEBI_df, on='_id', how='left')\n",
    "\n",
    "print(\"Number of train rows:\", len(train_df))\n",
    "print(\"True:\", len(train_df[train_df.label == True]), \"\\tFalse:\", len(train_df[train_df.label == False]))\n",
    "\n",
    "print(\"Number of validete rows:\", len(valid_df))\n",
    "print(\"True:\", len(valid_df[valid_df.label == True]), \"\\tFalse:\", len(valid_df[valid_df.label == False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki2vec = Wikipedia2Vec.load('../model/jawiki_20180420_300d.pkl')\n",
    "poincare_model = PoincareModel.load(\"../model/poincare.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2vec(s: str):\n",
    "    return [_w2v(w) for w in s]\n",
    "\n",
    "def _w2v(w):\n",
    "    try:\n",
    "        return np.array(wiki2vec.get_word_vector(w).tolist())\n",
    "    except KeyError:\n",
    "        return np.zeros(WORD_EMBEDDING_DIM)\n",
    "\n",
    "def ontology2vec(ChEBI: str):\n",
    "    '''\n",
    "    Using Poincar√© embedding.\n",
    "    '''\n",
    "    if ChEBI is np.nan:\n",
    "        return np.zeros(ONTOLOGY_EMBEDDING_DIM)\n",
    "    \n",
    "    try:\n",
    "        return poincare_model.kv[ChEBI]\n",
    "    except KeyError:\n",
    "        return np.zeros(ONTOLOGY_EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_words = pad_sequences(\n",
    "    train_df.words.apply(lambda x: sentence2vec(x)).tolist()\n",
    "    , dtype='float32'\n",
    "    , padding='post'\n",
    "    , truncating='pre'\n",
    "    , maxlen=50\n",
    ")\n",
    "\n",
    "X_train_ontology = train_df.ChEBI.apply(lambda x: ontology2vec(x)).tolist()\n",
    "X_train_ontology = np.array(X_train_ontology)\n",
    "\n",
    "y_train = train_df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_words = pad_sequences(\n",
    "    valid_df.words.apply(lambda x: sentence2vec(x)).tolist()\n",
    "    , dtype='float32'\n",
    "    , padding='post'\n",
    "    , truncating='pre'\n",
    "    , maxlen=50\n",
    ")\n",
    "\n",
    "X_valid_ontology = valid_df.ChEBI.apply(lambda x: ontology2vec(x)).tolist()\n",
    "X_valid_ontology = np.array(X_valid_ontology)\n",
    "\n",
    "y_valid = valid_df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8672, 50, 300)\n",
      "(8672, 10)\n",
      "(8672,)\n"
     ]
    }
   ],
   "source": [
    "# check dimensions\n",
    "print(X_train_words.shape)\n",
    "print(X_train_ontology.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        \n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        \n",
    "        return precision\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_EMBEDDING_DIM = 300\n",
    "WORD_LSTM_UNIT = 512\n",
    "ONTOLOGY_EMBEDDING_DIM = 10\n",
    "FC_DIM = 128\n",
    "DROPOUT_RATE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = Input(shape=(None, WORD_EMBEDDING_DIM,), dtype='float32')\n",
    "ontology_embeddings = Input(shape=(ONTOLOGY_EMBEDDING_DIM,), dtype='float32')\n",
    "\n",
    "l_lstm = Bidirectional(LSTM(WORD_LSTM_UNIT, return_sequences=True))(word_embeddings)\n",
    "l_max = Lambda(lambda x: K.max(x, axis=1))(l_lstm)\n",
    "x = concatenate([l_max, ontology_embeddings])\n",
    "\n",
    "x = Dropout(DROPOUT_RATE)(x)\n",
    "x = Dense(FC_DIM, activation='relu')(x)\n",
    "x = Dropout(DROPOUT_RATE)(x)\n",
    "x = Dense(FC_DIM, activation='relu')(x)\n",
    "x = Dropout(DROPOUT_RATE)(x)\n",
    "x = Dense(FC_DIM, activation='relu')(x)\n",
    "\n",
    "pred = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[word_embeddings, ontology_embeddings], outputs=pred)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[metrics.binary_accuracy, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "import pydot\n",
    "plot_model(model, show_shapes=True, to_file='model3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8672/8672 [==============================] - 5s 559us/step - loss: 1.1236 - binary_accuracy: 0.8148 - f1: 0.0939\n",
      "Epoch 2/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 1.1164 - binary_accuracy: 0.8523 - f1: 0.0947\n",
      "Epoch 3/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 1.0625 - binary_accuracy: 0.7979 - f1: 0.1658\n",
      "Epoch 4/100\n",
      "8672/8672 [==============================] - 3s 302us/step - loss: 0.9601 - binary_accuracy: 0.8018 - f1: 0.2732\n",
      "Epoch 5/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.8136 - binary_accuracy: 0.8285 - f1: 0.3798\n",
      "Epoch 6/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.7322 - binary_accuracy: 0.8461 - f1: 0.4235\n",
      "Epoch 7/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.6656 - binary_accuracy: 0.8624 - f1: 0.4540\n",
      "Epoch 8/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.6112 - binary_accuracy: 0.8720 - f1: 0.4724\n",
      "Epoch 9/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.5671 - binary_accuracy: 0.8773 - f1: 0.4920\n",
      "Epoch 10/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.5355 - binary_accuracy: 0.8790 - f1: 0.4973\n",
      "Epoch 11/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.5053 - binary_accuracy: 0.8810 - f1: 0.5008\n",
      "Epoch 12/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.5034 - binary_accuracy: 0.8707 - f1: 0.4920\n",
      "Epoch 13/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.4797 - binary_accuracy: 0.8715 - f1: 0.4992\n",
      "Epoch 14/100\n",
      "8672/8672 [==============================] - 3s 302us/step - loss: 0.4356 - binary_accuracy: 0.8818 - f1: 0.5188\n",
      "Epoch 15/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.3987 - binary_accuracy: 0.8951 - f1: 0.5521\n",
      "Epoch 16/100\n",
      "8672/8672 [==============================] - 3s 302us/step - loss: 0.3716 - binary_accuracy: 0.9008 - f1: 0.5693\n",
      "Epoch 17/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.4149 - binary_accuracy: 0.8787 - f1: 0.5232\n",
      "Epoch 18/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.3866 - binary_accuracy: 0.8989 - f1: 0.5749\n",
      "Epoch 19/100\n",
      "8672/8672 [==============================] - 3s 306us/step - loss: 0.3316 - binary_accuracy: 0.9062 - f1: 0.5840\n",
      "Epoch 20/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.3267 - binary_accuracy: 0.9097 - f1: 0.5965\n",
      "Epoch 21/100\n",
      "8672/8672 [==============================] - 3s 305us/step - loss: 0.3342 - binary_accuracy: 0.9046 - f1: 0.5856\n",
      "Epoch 22/100\n",
      "8672/8672 [==============================] - 3s 305us/step - loss: 0.3058 - binary_accuracy: 0.9157 - f1: 0.6173\n",
      "Epoch 23/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.3410 - binary_accuracy: 0.9128 - f1: 0.6127\n",
      "Epoch 24/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.3344 - binary_accuracy: 0.8999 - f1: 0.5805\n",
      "Epoch 25/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.2863 - binary_accuracy: 0.9171 - f1: 0.6233\n",
      "Epoch 26/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.2793 - binary_accuracy: 0.9220 - f1: 0.6315\n",
      "Epoch 27/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.2901 - binary_accuracy: 0.9182 - f1: 0.6222\n",
      "Epoch 28/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.2612 - binary_accuracy: 0.9283 - f1: 0.6533\n",
      "Epoch 29/100\n",
      "8672/8672 [==============================] - 3s 302us/step - loss: 0.2970 - binary_accuracy: 0.9101 - f1: 0.6076\n",
      "Epoch 30/100\n",
      "8672/8672 [==============================] - 3s 302us/step - loss: 0.2840 - binary_accuracy: 0.9287 - f1: 0.6618\n",
      "Epoch 31/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.2517 - binary_accuracy: 0.9304 - f1: 0.6594\n",
      "Epoch 32/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.2320 - binary_accuracy: 0.9361 - f1: 0.6803\n",
      "Epoch 33/100\n",
      "8672/8672 [==============================] - 3s 302us/step - loss: 0.2293 - binary_accuracy: 0.9370 - f1: 0.6836\n",
      "Epoch 34/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.2232 - binary_accuracy: 0.9402 - f1: 0.6934\n",
      "Epoch 35/100\n",
      "8672/8672 [==============================] - 3s 302us/step - loss: 0.2147 - binary_accuracy: 0.9395 - f1: 0.6887\n",
      "Epoch 36/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.2136 - binary_accuracy: 0.9411 - f1: 0.6989\n",
      "Epoch 37/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.2274 - binary_accuracy: 0.9450 - f1: 0.7163\n",
      "Epoch 38/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.2059 - binary_accuracy: 0.9403 - f1: 0.6967\n",
      "Epoch 39/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.1902 - binary_accuracy: 0.9480 - f1: 0.7240\n",
      "Epoch 40/100\n",
      "8672/8672 [==============================] - 3s 302us/step - loss: 0.2154 - binary_accuracy: 0.9408 - f1: 0.6992\n",
      "Epoch 41/100\n",
      "8672/8672 [==============================] - 3s 302us/step - loss: 0.2411 - binary_accuracy: 0.9333 - f1: 0.6806\n",
      "Epoch 42/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1928 - binary_accuracy: 0.9463 - f1: 0.7202\n",
      "Epoch 43/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1890 - binary_accuracy: 0.9496 - f1: 0.7289\n",
      "Epoch 44/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1892 - binary_accuracy: 0.9510 - f1: 0.7346\n",
      "Epoch 45/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.2042 - binary_accuracy: 0.9408 - f1: 0.6978\n",
      "Epoch 46/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1804 - binary_accuracy: 0.9521 - f1: 0.7410\n",
      "Epoch 47/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1592 - binary_accuracy: 0.9591 - f1: 0.7740\n",
      "Epoch 48/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.1861 - binary_accuracy: 0.9530 - f1: 0.7416\n",
      "Epoch 49/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1631 - binary_accuracy: 0.9540 - f1: 0.7483\n",
      "Epoch 50/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1787 - binary_accuracy: 0.9551 - f1: 0.7603\n",
      "Epoch 51/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1833 - binary_accuracy: 0.9525 - f1: 0.7399\n",
      "Epoch 52/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1778 - binary_accuracy: 0.9530 - f1: 0.7413\n",
      "Epoch 53/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1784 - binary_accuracy: 0.9564 - f1: 0.7600\n",
      "Epoch 54/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1531 - binary_accuracy: 0.9584 - f1: 0.7656\n",
      "Epoch 55/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1565 - binary_accuracy: 0.9632 - f1: 0.7888\n",
      "Epoch 56/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1537 - binary_accuracy: 0.9599 - f1: 0.7732\n",
      "Epoch 57/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1608 - binary_accuracy: 0.9614 - f1: 0.7783\n",
      "Epoch 58/100\n",
      "8672/8672 [==============================] - 3s 302us/step - loss: 0.1510 - binary_accuracy: 0.9599 - f1: 0.7756\n",
      "Epoch 59/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1496 - binary_accuracy: 0.9641 - f1: 0.7891\n",
      "Epoch 60/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.1373 - binary_accuracy: 0.9615 - f1: 0.7813\n",
      "Epoch 61/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1369 - binary_accuracy: 0.9655 - f1: 0.7965\n",
      "Epoch 62/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.1380 - binary_accuracy: 0.9644 - f1: 0.7933\n",
      "Epoch 63/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1440 - binary_accuracy: 0.9662 - f1: 0.8038\n",
      "Epoch 64/100\n",
      "8672/8672 [==============================] - 3s 305us/step - loss: 0.1445 - binary_accuracy: 0.9634 - f1: 0.7884\n",
      "Epoch 65/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.1320 - binary_accuracy: 0.9685 - f1: 0.8132\n",
      "Epoch 66/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1175 - binary_accuracy: 0.9686 - f1: 0.8143\n",
      "Epoch 67/100\n",
      "8672/8672 [==============================] - 3s 302us/step - loss: 0.1402 - binary_accuracy: 0.9666 - f1: 0.8005\n",
      "Epoch 68/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1184 - binary_accuracy: 0.9726 - f1: 0.8354\n",
      "Epoch 69/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.1302 - binary_accuracy: 0.9683 - f1: 0.8106\n",
      "Epoch 70/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1159 - binary_accuracy: 0.9698 - f1: 0.8190\n",
      "Epoch 71/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.1432 - binary_accuracy: 0.9623 - f1: 0.7862\n",
      "Epoch 72/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.1155 - binary_accuracy: 0.9713 - f1: 0.8269\n",
      "Epoch 73/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.1206 - binary_accuracy: 0.9709 - f1: 0.8238\n",
      "Epoch 74/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.1226 - binary_accuracy: 0.9699 - f1: 0.8191\n",
      "Epoch 75/100\n",
      "8672/8672 [==============================] - 3s 310us/step - loss: 0.1183 - binary_accuracy: 0.9696 - f1: 0.8166\n",
      "Epoch 76/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.1167 - binary_accuracy: 0.9711 - f1: 0.8249\n",
      "Epoch 77/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1414 - binary_accuracy: 0.9601 - f1: 0.7788\n",
      "Epoch 78/100\n",
      "8672/8672 [==============================] - 3s 305us/step - loss: 0.1252 - binary_accuracy: 0.9704 - f1: 0.8226\n",
      "Epoch 79/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1138 - binary_accuracy: 0.9721 - f1: 0.8325\n",
      "Epoch 80/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.0906 - binary_accuracy: 0.9766 - f1: 0.8546\n",
      "Epoch 81/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.1029 - binary_accuracy: 0.9734 - f1: 0.8388\n",
      "Epoch 82/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.0912 - binary_accuracy: 0.9779 - f1: 0.8614\n",
      "Epoch 83/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.0928 - binary_accuracy: 0.9772 - f1: 0.8543\n",
      "Epoch 84/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.0823 - binary_accuracy: 0.9799 - f1: 0.8741\n",
      "Epoch 85/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.0839 - binary_accuracy: 0.9803 - f1: 0.8750\n",
      "Epoch 86/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.0890 - binary_accuracy: 0.9788 - f1: 0.8665\n",
      "Epoch 87/100\n",
      "8672/8672 [==============================] - 3s 302us/step - loss: 0.0987 - binary_accuracy: 0.9756 - f1: 0.8448\n",
      "Epoch 88/100\n",
      "8672/8672 [==============================] - 3s 302us/step - loss: 0.0725 - binary_accuracy: 0.9812 - f1: 0.8792\n",
      "Epoch 89/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.0828 - binary_accuracy: 0.9825 - f1: 0.8845\n",
      "Epoch 90/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.0858 - binary_accuracy: 0.9758 - f1: 0.8507\n",
      "Epoch 91/100\n",
      "8672/8672 [==============================] - 3s 302us/step - loss: 0.0897 - binary_accuracy: 0.9796 - f1: 0.8700\n",
      "Epoch 92/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.0715 - binary_accuracy: 0.9845 - f1: 0.9015\n",
      "Epoch 93/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.0714 - binary_accuracy: 0.9832 - f1: 0.8915\n",
      "Epoch 94/100\n",
      "8672/8672 [==============================] - 3s 304us/step - loss: 0.0798 - binary_accuracy: 0.9805 - f1: 0.8770\n",
      "Epoch 95/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.0784 - binary_accuracy: 0.9797 - f1: 0.8711\n",
      "Epoch 96/100\n",
      "8672/8672 [==============================] - 3s 302us/step - loss: 0.0718 - binary_accuracy: 0.9812 - f1: 0.8790\n",
      "Epoch 97/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.0822 - binary_accuracy: 0.9819 - f1: 0.8844\n",
      "Epoch 98/100\n",
      "8672/8672 [==============================] - 3s 301us/step - loss: 0.1012 - binary_accuracy: 0.9734 - f1: 0.8394\n",
      "Epoch 99/100\n",
      "8672/8672 [==============================] - 3s 303us/step - loss: 0.0822 - binary_accuracy: 0.9803 - f1: 0.8760\n",
      "Epoch 100/100\n",
      "8672/8672 [==============================] - 3s 302us/step - loss: 0.0928 - binary_accuracy: 0.9787 - f1: 0.8671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f64cdfec630>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[X_train_words, X_train_ontology], y=y_train, class_weight={0:1, 1: 10}, epochs=100, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(pred_true, pred_false):\n",
    "    TP = pred_true[pred_true.label == True].count()[0]\n",
    "    FP = pred_true[pred_true.label == False].count()[0]\n",
    "    TN = pred_false[pred_false.label == False].count()[0]\n",
    "    FN = pred_false[pred_false.label == True].count()[0]\n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    print(\"TP:\", TP, \"\\tFP:\", FP, \"\\tTN:\", TN, \"\\tFN:\", FN)\n",
    "    print(\"Precision:\", precision, \"\\tRecall:\", recall, \"\\tF1:\", F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict([X_valid_words, X_valid_ontology])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 54 \tFP: 50 \tTN: 1765 \tFN: 49\n",
      "Precision: 0.5192307692307693 \tRecall: 0.5242718446601942 \tF1: 0.5217391304347825\n"
     ]
    }
   ],
   "source": [
    "pred_true = valid_df.loc[np.where(predict >= 0.5)[0]]\n",
    "pred_false = valid_df.loc[np.where(predict < 0.5)[0]]\n",
    "pred_true_uniq = pred_true.drop_duplicates(['_id', 'sentence'])\n",
    "pred_false_uniq = pred_false.drop_duplicates(['_id', 'sentence'])\n",
    "\n",
    "evaluation(pred_true, pred_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_true.loc[:, ['title', 'sentence', 'ChEBI', 'label']].to_csv(\"../dump/pred_true.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_false[pred_false.label == True].loc[:, ['title', 'sentence', 'ChEBI', 'label']].to_csv(\"../dump/pred_false_filter_label_true.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['N-„É°„ÉÅ„É´„Éî„É≠„É™„Éâ„É≥',\n",
       "        'N-„É°„ÉÅ„É´-2-„Éî„É≠„É™„Éâ„É≥„ÅØ„ÄÅŒ≥-„Éñ„ÉÅ„É≠„É©„ÇØ„Éà„É≥„Å®„É°„ÉÅ„É´„Ç¢„Éü„É≥„Å®„ÇíÁ∏ÆÂêà„Åï„Åõ„Å¶Âæó„Çã È´ò„ÅÑÊ∫∂Ëß£ÊÄß„ÇíÊåÅ„Å§„Åü„ÇÅ„ÄÅÁâπ„Å´È´òÂàÜÂ≠êÂåñÂ≠¶„ÅÆÂàÜÈáé„Çí‰∏≠ÂøÉ„Å´Êßò„ÄÖ„Å™Áâ©Ë≥™„Å´ÂØæ„Åô„ÇãÊ∫∂Â™í„Å®„Åó„Å¶Áî®„ÅÑ„Çâ„Çå„Çã„ÄÇ'],\n",
       "       ['„Çπ„ÉÅ„É¨„É≥',\n",
       "        '„Åã„Å§„Å¶„ÅØ„ÄÅ„Ç®„ÉÅ„É´„Éô„É≥„Çº„É≥„ÇíÂ°©Á¥†Âåñ„Åó„Åü„ÅÆ„Å°„Å´ËÑ±Â°©ÂåñÊ∞¥Á¥†„Åß„Ç™„É¨„Éï„Ç£„É≥„Å®„Åô„ÇãÊñπÊ≥ï„ÇÑ„Ç®„ÉÅ„É´„Éô„É≥„Çº„É≥„ÇíÈÖ∏Âåñ„Åó„Åü„Ç¢„Çª„Éà„Éï„Çß„Éé„É≥„ÄÅÈÇÑÂÖÉ„Åó„Åü„Éï„Çß„Éã„É´„Ç´„É´„Éì„Éé„Éº„É´„ÇíÁµåÁî±„Åó„Å¶ËÑ±Ê∞¥ÂèçÂøú„Ç™„É¨„Éï„Ç£„É≥„Å®„Åô„ÇãÊñπÊ≥ï„Å™„Å©„ÇÇÂ≠òÂú®„Åó„Åü„Åå„ÄÅ‰ªäÊó•„Åß„ÅØÁµåÊ∏àÁöÑ„Å™ÁêÜÁî±„ÅßËß¶Â™í„Å´„Çà„ÇäËÑ±Ê∞¥Á¥†„Åô„ÇãÊñπÊ≥ï‰ª•Â§ñ„ÅØÂà©Áî®„Åï„Çå„Å™„ÅÑ„ÄÇ'],\n",
       "       ['„Éï„É´„Ç™„É¨„Çª„Ç§„É≥', 'ÂèçÂøúËß¶Â™í„Å®„Åó„Å¶„ÅØ„ÄÅÂ°©Âåñ‰∫úÈâõ„ÅÆ‰ªñ„Å´„Çπ„É´„Éõ„É≥ÈÖ∏„ÇÇÁî®„ÅÑ„Çâ„Çå„Çã„ÄÇ'],\n",
       "       ['„Éï„É´„Ç™„É¨„Çª„Ç§„É≥', 'ÂèçÂøúËß¶Â™í„Å®„Åó„Å¶„ÅØ„ÄÅÂ°©Âåñ‰∫úÈâõ„ÅÆ‰ªñ„Å´„Çπ„É´„Éõ„É≥ÈÖ∏„ÇÇÁî®„ÅÑ„Çâ„Çå„Çã„ÄÇ'],\n",
       "       ['ÁÇ≠ÈÖ∏„Éô„É™„É™„Ç¶„É†',\n",
       "        'Be ( OH ) 2 + CO 2 + 3 H 2 O ‚ü∂ BeCO 3 ‚ãÖ 4 H 2 O Ê∞¥ÈÖ∏Âåñ„Éô„É™„É™„Ç¶„É†„Çí„Ç¢„É≥„É¢„Éã„Ç¢Ê∞¥„Å´Êá∏ÊøÅ„Åï„Åõ„Å¶‰∫åÈÖ∏ÂåñÁÇ≠Á¥†„ÇíÈÄö„Åò„Å¶È£ΩÂíå„Åï„Åõ„ÄÅÊîæÁΩÆ„Åô„Çã„Å®Â°©Âü∫ÊÄßÂ°©Be2CO3(OH)2„ÅåÊ≤àÊÆø„Åô„Çã„ÄÇ'],\n",
       "       ['Â°©Âåñ„Ç¶„É©„É≥(VI)', 'ÈÖ∏Âåñ„Ç¶„É©„É≥(VI)„ÅØ„Åæ„ÅöÂ°©Âåñ„Ç¶„É©„É≥(V)„Å®„Å™„Çä„ÄÅ„Åï„Çâ„Å´Â°©Á¥†„Å®ÂèçÂøú„Åó„Å¶Â°©Âåñ„Ç¶„É©„É≥(VI)„Å®„Å™„Çã„ÄÇ'],\n",
       "       ['Â°©Âåñ„Ç¶„É©„É≥(VI)', 'ÂèçÂøú„Å´‰º¥„Å£„Å¶ÂúßÂäõ„ÅåÂ§âÂåñ„Åô„Çã„Åü„ÇÅ„ÄÅ„Ç∞„É≠„Éº„Éñ„Éú„ÉÉ„ÇØ„Çπ„Å™„Å©„ÅÆÊ∞óÂØÜÂÆπÂô®‰∏≠„ÅßÂèçÂøú„Åï„Åõ„Çã„ÄÇ'],\n",
       "       ['„Ç®„Éº„ÉÜ„É´ (ÂåñÂ≠¶)', '„Ç¢„É´„Ç≥„Éº„É´„ÅÆÂÖ±Â≠ò‰∏ã„ÄÅ„Ç™„É¨„Éï„Ç£„É≥„Å´Ê±ÇÈõªÂ≠êÂâ§„Çí‰ΩúÁî®„Åï„Åõ„Çã„Å®Ê±ÇÈõªÂ≠êÁöÑ‰ªòÂä†ÂèçÂøú„Å´„Çà„Çä„Ç®„Éº„ÉÜ„É´„ÅåÂæó„Çâ„Çå„Çã„ÄÇ'],\n",
       "       ['„Ç§„Éé„Ç∑„Éà„Éº„É´„Éà„É™„Çπ„É™„É≥ÈÖ∏',\n",
       "        'Á¥∞ËÉûËÜú„Å´Â≠òÂú®„Åô„Çã„É™„É≥ËÑÇË≥™„Åß„ÅÇ„Çã„Éõ„Çπ„Éï„Ç°„ÉÅ„Ç∏„É´„Ç§„Éé„Ç∑„Éà„Éº„É´4,5-„Éì„Çπ„É™„É≥ÈÖ∏„Åå„Éõ„Çπ„Éõ„É™„Éë„Éº„ÇºC„Å´„Çà„Å£„Å¶Âä†Ê∞¥ÂàÜËß£„Åï„Çå„Çã„Å®„ÄÅ IP3„Å®„Ç∏„Ç¢„Ç∑„É´„Ç∞„É™„Çª„É≠„Éº„É´„ÅåÁîüÊàê„Åô„Çã„ÄÇ'],\n",
       "       ['„Éá„Ç´„Ç´„É´„Éú„Éã„É´„Ç∏„Éí„Éâ„É™„Éâ‰∏â„Ç™„Çπ„Éü„Ç¶„É†',\n",
       "        'Os3(CO)12 „ÅÆ„Ç™„ÇØ„Çø„É≥Ê∫∂Ê∂≤Ôºà„Åæ„Åü„ÅØ‰ºº„ÅüÊ≤∏ÁÇπ„Çí„ÇÇ„Å§‰∏çÊ¥ªÊÄßÊ∫∂Â™íÔºâ„Çí H2 „Åß„Éë„Éº„Ç∏„Åô„Çã„Åì„Å®„Å´„Çà„Å£„Å¶Ê∫ñÂÇô„Åï„Çå„Çã„ÄÇ'],\n",
       "       ['„Çµ„ÉÉ„Ç´„É™„É≥', 'ÂÖÉ„ÅØ„Éà„É´„Ç®„É≥„Åã„ÇâÂêàÊàê„Åï„Çå„Åü„Åå„ÄÅÂèéÁéá„ÅØ‰Ωé„Åã„Å£„Åü„ÄÇ'],\n",
       "       ['„Çµ„ÉÉ„Ç´„É™„É≥', '2-„ÇØ„É≠„É≠„Éà„É´„Ç®„É≥„Åã„Çâ„ÇÇ‰Ωú„Çã„Åì„Å®„ÇÇ„Åß„Åç„Çã„ÄÇ'],\n",
       "       ['„Ç∑„Ç¨„Éà„Ç≠„Ç∑„É≥', '„ÅÇ„ÇãÁ®Æ„ÅÆËóªÈ°ûÔºàÊúâÊØíÊ∏¶Èû≠ÊØõËóªÔºâ„Åå„Å§„Åè„ÇäÈ≠öÈ°û„Å´ËìÑÁ©ç„Åï„Çå„Çã„ÄÇ'],\n",
       "       ['„Ç∑„Ç¨„Éà„Ç≠„Ç∑„É≥', '„Éù„É™„Ç±„ÉÅ„ÉâÁµåË∑Ø„Å´„Çà„Å£„Å¶ÁîüÂêàÊàê„Åï„Çå„ÄÅ‰∏≠Âì°Áí∞„ÇíÂê´„ÇÄÂ§öÊï∞„ÅÆ„Ç®„Éº„ÉÜ„É´Áí∞„ÅåÈÄ£Áµê„Åó„ÅüÁâπÁï∞„Å™ÊßãÈÄ†„ÇíÊåÅ„Å§„ÄÇ'],\n",
       "       ['„Ç∑„Ç¨„Éà„Ç≠„Ç∑„É≥',\n",
       "        '„Ç∞„É©„Éñ„ÇπËß¶Â™í„ÇíÁî®„ÅÑ„Åü„Ç™„É¨„Éï„Ç£„É≥„É°„Çø„Çª„Ç∑„Çπ„Å´„Çà„ÇãÈñâÁí∞ÂèçÂøú„ÇíÈçµÂèçÂøú„Å®„Åó„ÄÅ13ÂÄã„ÅÆÈÄ£Áµê„Åó„Åü„Ç®„Éº„ÉÜ„É´Áí∞ÊßãÈÄ†„ÇíÂäπÁéáÁöÑ„Å´ÂêàÊàê„Åô„ÇãÊâãÊ≥ï„ÇíÁ¢∫Á´ã„Åó„ÄÅ‰ª•Âæå„ÅÆÂ§©ÁÑ∂Áâ©ÂêàÊàê„Å´„Åä„Åë„ÇãÂèØËÉΩÊÄß„ÇíÂ∫É„Åí„Åü„ÄÇ'],\n",
       "       ['„Éö„É≥„Çø„Çª„É≥',\n",
       "        '„Åù„ÅÆÂæå„ÄÅ„Éö„É≥„Çø„Çª„É≥„ÅÆËñÑÂ±§„ÇíË™øË£Ω„Åô„ÇãÂøÖË¶Å„ÅåÁîü„Åò„Çã„Å®„ÄÅÂâçÈßÜ‰Ωì„Åã„ÇâÂ∞èÂàÜÂ≠ê„ÇíËÑ±Èõ¢„Åï„Åõ„ÇãÊâãÊ≥ï„ÇíÁî®„ÅÑ„Å¶ÂêàÊàê„Åï„Çå„Çã„Çà„ÅÜ„Å´„Å™„Å£„Åü„ÄÇ'],\n",
       "       ['„Éö„É≥„Çø„Çª„É≥',\n",
       "        '„Éö„É≥„Çø„Çª„É≥„ÅØ‰∏ÄËà¨ÁöÑ„Å™ÊúâÊ©üÊ∫∂Â™í„Å´„ÅØÊ∫∂„Åë„Å´„Åè„ÅÑ„Åå„ÄÅ1,2,4-„Éà„É™„ÇØ„É≠„É≠„Éô„É≥„Çº„É≥„ÅÆ„Çà„ÅÜ„Å™„Éè„É≠„Ç≤„É≥ÂåñËä≥È¶ôÊóèÁÇ≠ÂåñÊ∞¥Á¥†Á≥ªÊ∫∂Â™í‰∏≠„Å´È´òÊ∏©„Åß„ÅØÊ∫∂„Åë„Çã„Åì„Å®„ÅåÁü•„Çâ„Çå„Å¶„ÅÑ„Çã„ÄÇ'],\n",
       "       ['„Éö„É≥„Çø„Çª„É≥', '„Åù„Åì„Åã„ÇâÂ∞è„Åï„Å™Âπ≥Êùø„ÇíÂΩ¢Êàê„Åï„Åõ„Çã„Åü„ÇÅ„Å´ÁµêÊô∂Âåñ„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Çã„ÄÇ'],\n",
       "       ['„Éá„Ç≠„Çπ„Éà„É©„É≥',\n",
       "        '„Éá„Ç≠„Çπ„Éà„É©„É≥ (dextran) „ÅØ„Ç∞„É´„Ç≥„Éº„Çπ„ÅÆ„Åø„Åã„Çâ„Å™„ÇãÂ§öÁ≥ñÈ°û„ÅÆ‰∏ÄÁ®Æ„Åß„ÄÅ„Çπ„ÇØ„É≠„Éº„Çπ„ÇíÂéüÊñô„Å®„Åó„Å¶‰π≥ÈÖ∏Ëèå„ÅåÁîüÁî£„Åô„Çã„ÄÇ'],\n",
       "       ['„Éà„É™„Ç§„ÇΩ„Éó„É≠„Éî„É´„Ç¢„Éü„É≥', '„Çà„Å£„Å¶„ÄÅ„Ç∏„Ç§„ÇΩ„Éó„É≠„Éî„É´„Ç¢„Éü„É≥„ÇíÂéüÊñô„Å´ÂêàÊàê„Åô„ÇãÊñπÊ≥ï„ÅåÁô∫Ë¶ã„Åï„Çå„Å¶„ÅÑ„ÇãÔºà‰∏ãÂºèÂèÇÁÖßÔºâ„ÄÇ'],\n",
       "       ['Á°´ÈÖ∏„Ç´„É´„Ç∑„Ç¶„É†', '66‚ÑÉ‰ª•‰∏ã„Åß„ÅØ2Ê∞¥ÂíåÁâ©„ÄÅ‰ª•‰∏ä„Åß„ÅØÁÑ°Ê∞¥Áâ©„ÅåÊûêÂá∫„Åô„Çã„ÄÇ'],\n",
       "       ['„Ç∞„É´„Ç≥„Éé„É©„ÇØ„Éà„É≥', 'Áîü‰ΩìÂÜÖ„Åß„ÅØ„Ç∞„É´„Ç≥„Éº„Çπ-1-„Éá„Éí„Éâ„É≠„Ç≤„Éä„Éº„Çº„ÅÆ‰ΩúÁî®„Å´„Çà„Çä„Ç∞„É´„Ç≥„Éº„Çπ„Åã„ÇâÂ§âÊèõ„Åï„Çå„Çã„ÄÇ'],\n",
       "       ['„Ç§„Ç™„Éé„É≥', '„Åæ„Åü„ÄÅ‰∏â„Éï„ÉÉÂåñ„Éõ„Ç¶Á¥†„Çí‰Ωø„ÅÜ„Å®Œ≥-„Ç§„Ç™„Éé„É≥„ÅåÁîüÊàê„Åô„Çã„ÄÇ'],\n",
       "       ['„Ç®„ÉÅ„É¨„É≥„ÉÜ„Éà„É©„Ç´„É´„Éú„É≥ÈÖ∏‰∫åÁÑ°Ê∞¥Áâ©',\n",
       "        '„Ç®„ÉÅ„É¨„É≥„ÉÜ„Éà„É©„Ç´„É´„Éú„É≥ÈÖ∏„ÅÆÁÜ±ÂàÜËß£„Å´„Çà„ÇãÁîüÊàê„ÅØ„ÄÅ1981Âπ¥„Å´„Ç∏„Éß„É≥„Éª„Éë„Çø„Éº„ÇΩ„É≥„Çâ„Å´„Çà„Å£„Å¶Â†±Âëä„Åï„Çå„Åü„ÄÇ'],\n",
       "       ['„É™„É≥ÈÖ∏‰∏â„Ç´„É´„Ç∑„Ç¶„É†', 'È™®„ÇíÁáÉÁÑº„Åï„Åõ„ÅüÈöõ„Å´Âæó„Çâ„Çå„ÇãÁâ©Ë≥™„Åß„ÇÇ„ÅÇ„ÇãÔºàÈ™®ÁÅ∞„ÉªÈ™®ÁÇ≠„Å™„Å©Ôºâ„ÄÇ'],\n",
       "       ['„Ç§„ÇΩ„Éñ„ÉÅ„É´„Ç¢„Éü„É≥', 'Â§©ÁÑ∂„Å´„ÅØ„ÄÅ‰∏ÄÈÉ®„ÅÆÊ§çÁâ©„ÇÑËóªÈ°û„Å´„Çà„ÇäËá™ÁÑ∂Áô∫Áîü„Åô„Çã„ÄÇ'],\n",
       "       ['REBCO',\n",
       "        'ÈõªÂ≠ê„Éì„Éº„É†ÂÖ±Ëí∏ÁùÄÊ≥ï ÈõªÂ≠ê„Éì„Éº„É†ÂÖ±Ëí∏ÁùÄÊ≥ï„ÅØ„ÄÅÂêÑÂÖÉÁ¥†„Åî„Å®„Å´Ëí∏ÁùÄ„É¨„Éº„Éà„ÇíÊ±∫ÂÆö„Åô„Çã„Åì„Å®„Åå„Åß„Åç„ÄÅÁµÑÊàêÂà∂Âæ°„ÅåÂÆπÊòì„Å´Ë°å„Åà„ÇãÊñπÊ≥ï„Åß„ÅÇ„Çã„ÄÇ'],\n",
       "       ['REBCO',\n",
       "        'ÁúüÁ©∫ÂÆπÂô®ÂÜÖ„ÅßË§áÊï∞„ÅÆËí∏ÁùÄÊ∫ê„ÇíÂÄã„ÄÖ„Å´ÈõªÂ≠ê„Éì„Éº„É†„ÅßÂä†ÁÜ±Ëí∏Áô∫„Åï„Åõ„ÄÅ„Éí„Éº„Çø„Éº„Å´„Çà„Å£„Å¶Âä†ÁÜ±„Åï„Çå„ÅüÂü∫Êùø‰∏ä„Å´ËñÑËÜú„Å®„Åó„Å¶ÊàêÈï∑„Åï„Åõ„Çã„ÄÇ'],\n",
       "       ['REBCO',\n",
       "        '„É¨„Éº„Ç∂„Ç¢„Éñ„É¨„Éº„Ç∑„Éß„É≥(PLD)Ê≥ï PLDÊ≥ï„ÅØPVD(Áâ©ÁêÜÊ∞óÁõ∏Ëí∏ÁùÄ)Ê≥ï„ÅÆ‰∏ÄÁ®Æ„Åß„ÄÅË£ÖÁΩÆËá™‰Ωì„ÅØ‰ªñ„ÅÆPVDËñÑËÜú‰ΩúË£ΩÊäÄË°ì„Å®ÊØî„Åπ„ÄÅÊúÄ„ÇÇÂçòÁ¥î„ÅßËñÑËÜú‰ΩúË£Ω„ÇÇÂÆπÊòì„ÅßÂ†ÜÁ©ç„Åï„Åõ„ÅüËñÑËÜú„ÅÆÁµÑÊàê„Åå„Çø„Éº„Ç≤„ÉÉ„Éà„Å´Ëøë„Åè„ÄÅ„É¨„Éº„Ç∂ÂÖâ„ÇíÂê∏Âèé„Åô„ÇãÁâ©Ë≥™„Åß„ÅÇ„Çå„Å∞È´òËûçÁÇπ„ÅÆÁâ©Ë≥™„Åß„ÇÇÂÆπÊòì„Å´ËñÑËÜúÂåñ„Åß„Åç„Çã„Å®„ÅÑ„ÅÜÂà©ÁÇπ„ÇíÊúâ„Åô„ÇãÊñπÊ≥ï„Åß„ÄÅÁúüÁ©∫„ÉÅ„É£„É≥„Éê„ÉºÂÜÖ„ÅÆÁÑºÁµê‰Ωì„Çø„Éº„Ç≤„ÉÉ„Éà„Å´„Éë„É´„Çπ„É¨„Éº„Ç∂„ÇíÊñ≠Á∂öÁöÑ„Å´ÁÖßÂ∞Ñ„Åó„Å¶„Çø„Éº„Ç≤„ÉÉ„Éà„Çí„Ç¢„Éñ„É¨„Éº„Ç∑„Éß„É≥„Åô„Çã„Åì„Å®„Å´„Çà„ÇäÊîæÂá∫„Åï„Çå„Çã„Éï„É©„Ç∞„É°„É≥„ÉàÔºà„Ç§„Ç™„É≥„ÄÅ„ÇØ„É©„Çπ„Çø„ÄÅÂàÜÂ≠ê„ÄÅÂéüÂ≠êÔºâ„Çí„Çø„Éº„Ç≤„ÉÉ„Éà„Å®ÂØæÂêë„Åó„Å¶ÈÖçÁΩÆ„Åï„Çå„ÅüÂü∫Êùø‰∏ä„Å´ËñÑËÜú„ÇíÂ†ÜÁ©ç„Åï„Åõ„Çã„ÄÇ'],\n",
       "       ['REBCO',\n",
       "        'ÊúâÊ©üÈáëÂ±ûÂåñÂ≠¶Ê∞óÁõ∏Ëí∏ÁùÄÊ≥ï(MOCVD) È´òÁúüÁ©∫„ÇíÂøÖË¶Å„Å®„Åõ„Åö„ÄÅÂ§ßÈù¢Á©ç„ÄÅË§áÈõë„Å™ÂΩ¢Áä∂„ÅÆÂü∫Êùø„Å´„ÇÇÊàêËÜú„ÅåÂèØËÉΩ„ÅßÁîüÁî£ÊÄß„ÅåÈ´ò„Åè„ÄÅÈáèÁî£ÊÄß„Å´ÂÑ™„Çå„Å¶„ÅÑ„ÇãÊñπÊ≥ï„Åß„ÅÇ„Çã„ÄÇ'],\n",
       "       ['REBCO',\n",
       "        'ÂéüÊñôÊßΩ„Å´ÂÖ•„Çå„ÅüÈáëÂ±ûÈåØ‰ΩìÂéüÊñô„Çí„Éí„Éº„Çø„Éº„ÅßÂä†ÁÜ±„ÅóÊ∂≤‰ΩìÁä∂ÊÖã„Å´„Åó„ÄÅ„Ç≠„É£„É™„Ç¢„Ç¨„Çπ„ÇíÂéüÊñôÊßΩÂÜÖ„Å´ÊµÅÈÄö„Åô„Çã„Åì„Å®„Å´„Çà„Çä„ÄÅÊ∞óÂåñ„Åó„ÅüÂéüÊñô„Ç¨„Çπ„ÇíÂèçÂøúÂÆ§„Å∏„Å®Â∞é„Åç„ÄÅ„Çª„É©„Éü„ÉÉ„ÇØ„Éí„Éº„Çø„Éº„ÅßÂä†ÁÜ±„Åï„Çå„ÅüÂü∫Êùø‰∏ä„Å´Ëí∏ÁùÄ„Åï„ÅõÊàêËÜú„ÇíË°å„ÅÜ„ÄÇ'],\n",
       "       ['Ê∞¥ÈÖ∏Âåñ„Éô„É™„É™„Ç¶„É†',\n",
       "        '„Éô„É™„É™„Ç¶„É†Â°©Ê∞¥Ê∫∂Ê∂≤„Å´„Ç¢„É≥„É¢„Éã„Ç¢Ê∞¥„ÇíÂä†„Åà„Å¶„Åß„Åç„ÇãÊ≤àÊÆø„Çí„ÄÅ„Ç¢„É≥„É¢„Éã„Ç¢Ê∞¥„ÅÆÂ≠òÂú®‰∏ã„ÅßÈï∑ÊôÇÈñìÂä†ÁÜ±„Åô„Çã„Å®Œ±Âûã„ÅÆÁµêÊô∂„ÅåÁîüÊàê„Åô„Çã„ÄÇ'],\n",
       "       ['„Éë„ÉÅ„Éß„É≠„Éº„É´', '„Éë„ÉÅ„Éß„É≠„Éº„É´ (Patchoulol) „ÅØ„ÄÅ„Éë„ÉÅ„Éß„É™„Åã„ÇâÊäΩÂá∫„Åï„Çå„Çã„Çª„Çπ„Ç≠„ÉÜ„É´„Éö„É≥„Ç¢„É´„Ç≥„Éº„É´„Åß„ÅÇ„Çã„ÄÇ'],\n",
       "       ['Â∞øÁ¥†', 'Áîü‰ΩìÂÜÖ„Åß„ÅØ„ÄÅÂ∞øÁ¥†ÂõûË∑Ø„Å´„Çà„Çä„Ç¢„É≥„É¢„Éã„Ç¢„Åã„ÇâÂ∞øÁ¥†„ÅåÁî£Áîü„Åï„Çå„Çã„ÄÇ'],\n",
       "       ['Â∞øÁ¥†', 'Áîü‰ΩìÂÜÖ„Åß„ÅØ„ÄÅÂ∞øÁ¥†ÂõûË∑Ø„Å´„Çà„Çä„Ç¢„É≥„É¢„Éã„Ç¢„Åã„ÇâÂ∞øÁ¥†„ÅåÁî£Áîü„Åï„Çå„Çã„ÄÇ'],\n",
       "       ['Â∞øÁ¥†', 'Áîü‰ΩìÂÜÖ„Åß„ÅØ„ÄÅÂ∞øÁ¥†ÂõûË∑Ø„Å´„Çà„Çä„Ç¢„É≥„É¢„Éã„Ç¢„Åã„ÇâÂ∞øÁ¥†„ÅåÁî£Áîü„Åï„Çå„Çã„ÄÇ'],\n",
       "       ['Â∞øÁ¥†', 'Áîü‰ΩìÂÜÖ„Åß„ÅØ„ÄÅÂ∞øÁ¥†ÂõûË∑Ø„Å´„Çà„Çä„Ç¢„É≥„É¢„Éã„Ç¢„Åã„ÇâÂ∞øÁ¥†„ÅåÁî£Áîü„Åï„Çå„Çã„ÄÇ'],\n",
       "       ['Â∞øÁ¥†', '„Åì„ÅÆÂêàÊàêÊ≥ï„ÅØ„É¥„Çß„Éº„É©„ÉºÂêàÊàê„Å®Âëº„Å∞„Çå„Å¶„ÅÑ„Çã„ÄÇ'],\n",
       "       ['Â∞øÁ¥†', '„Åì„ÅÆÂêàÊàêÊ≥ï„ÅØ„É¥„Çß„Éº„É©„ÉºÂêàÊàê„Å®Âëº„Å∞„Çå„Å¶„ÅÑ„Çã„ÄÇ'],\n",
       "       ['Â∞øÁ¥†', '„Åì„ÅÆÂêàÊàêÊ≥ï„ÅØ„É¥„Çß„Éº„É©„ÉºÂêàÊàê„Å®Âëº„Å∞„Çå„Å¶„ÅÑ„Çã„ÄÇ'],\n",
       "       ['Â∞øÁ¥†', '„Åì„ÅÆÂêàÊàêÊ≥ï„ÅØ„É¥„Çß„Éº„É©„ÉºÂêàÊàê„Å®Âëº„Å∞„Çå„Å¶„ÅÑ„Çã„ÄÇ'],\n",
       "       ['„Çπ„ÉØ„Ç§„É≥„ÇΩ„Éã„É≥',\n",
       "        '„Çπ„ÉØ„Ç§„É≥„ÇΩ„Éã„É≥„ÅØÂïÜÊ•≠ÁöÑ„Å´„ÅØ„É°„Çø„É™„Ç∏„Ç¶„É†(Metarhizium anisopliae„Å™„Å©„ÅÑ„Åè„Å§„Åã„ÅÆÊ§çÁâ©„Åä„Çà„Å≥Ëèå„Åã„ÇâÊäΩÂá∫„Åï„Çå„Çã‰ªñ„ÄÅÂÖ®ÂêàÊàê„ÇÇÂ§öÊï∞Â†±Âëä„Åï„Çå„Å¶„ÅÑ„Çã„ÄÇ'],\n",
       "       ['„Ç∑„Ç¢„É≥ÂåñÊ∞¥ÈäÄ(II)',\n",
       "        '„Ç∑„Ç¢„É≥ÂåñÊ∞¥ÈäÄ(I)„ÅØ„ÄÅÊ∞¥ÈäÄ(I)„Ç§„Ç™„É≥„ÅÆÊ∞¥Ê∫∂Ê∂≤„Å´„Ç∑„Ç¢„É≥Âåñ„Ç´„É™„Ç¶„É†Ê∞¥Ê∫∂Ê∂≤„Å™„Å©„ÇíÊª¥‰∏ã„Åó„Åü„Å®„Åç„Å´Áîü„Åò„Çã„Åå„ÄÅ„Åì„ÅÆÁâ©Ë≥™„ÅØ‰∏çÂÆâÂÆö„Åß„ÅÇ„Çä„ÄÅ„Åü„Å†„Å°„Å´ÂàÜËß£„Åó„Å¶„Ç∑„Ç¢„É≥ÂåñÊ∞¥ÈäÄ(II)„Å®Ê∞¥ÈäÄ„Å´„Å™„Çã„ÄÇ'],\n",
       "       ['Â°©Âåñ„É≠„Ç∏„Ç¶„É†(III)',\n",
       "        '2 Rh + 3 Cl 2 ‚ü∂ 2 RhCl 3 Â°©Âåñ„É≠„Ç∏„Ç¶„É†‰∏âÊ∞¥ÂíåÁâ©„ÇíÂ°©ÂåñÊ∞¥Á¥†‰∏≠„Åß360‚ÑÉ„ÅßÂä†ÁÜ±ÂàÜËß£„Åô„Çã„Å®Ê∞¥„Å´‰∏çÊ∫∂ÊÄß„ÅÆÁÑ°Ê∞¥Áâ©„ÅåÂæó„Çâ„Çå„Çã„ÄÇ'],\n",
       "       ['Â°©Âåñ„É≠„Ç∏„Ç¶„É†(III)', '‰∏ÄÊñπÂ°©ÂåñÊ∞¥Á¥†‰∏≠„ÅÆ180‚ÑÉ„ÅÆÂä†ÁÜ±„Åß„ÅØÊ∞¥Ê∫∂ÊÄß„ÅÆÁÑ°Ê∞¥Áâ©„ÅåÂæó„Çâ„Çå„Çã„ÄÇ'],\n",
       "       ['„É°„ÉÅ„É´„Éõ„Çπ„Éõ„É≥ÈÖ∏„Ç∏„É°„ÉÅ„É´',\n",
       "        '‰∫ú„É™„É≥ÈÖ∏„Éà„É™„É°„ÉÅ„É´„Å®„Éè„É≠„É°„Çø„É≥Ôºà„É®„Éº„Éâ„É°„Çø„É≥Á≠âÔºâ„ÇíÁî®„ÅÑ„Åü„Éü„Ç´„Ç®„É™„Çπ„Éª„Ç¢„É´„Éñ„Éº„Çæ„ÉïÂèçÂøú„Å´„Çà„ÇäË£ΩÈÄ†„ÅåÂèØËÉΩ„Åß„ÅÇ„Çã„ÄÇ'],\n",
       "       ['„ÉÅ„Ç™„Ç¢„Éü„Éâ', 'Â§ö„Åè„ÅÆÂ†¥Âêà„ÄÅ„Ç¢„Éü„Éâ„ÅÆÈÖ∏Á¥†„ÇíÁ°´ÈªÑ„Å´ÁΩÆÊèõ„Åó„Å¶ÂêàÊàê„Åô„Çã„ÄÇ'],\n",
       "       ['„ÉÅ„Ç™„Ç¢„Éü„Éâ',\n",
       "        '„Åã„Å§„Å¶„ÅØ„Ç¢„Éü„Éâ„Å®‰∫îÁ°´Âåñ‰∫å„É™„É≥ (P2S5) „ÇíÂä†ÁÜ±„Åô„ÇãÊñπÊ≥ï„ÅåÂèñ„Çâ„Çå„Å¶„ÅÑ„Åü„Åå„ÄÅËøëÂπ¥„Åß„ÅØ„Çà„ÇäÁ©èÂíå„Å™Êù°‰ª∂„ÅßÂèçÂøú„ÅåÈÄ≤Ë°å„Åô„Çã„É≠„Éº„ÇΩ„É≥Ë©¶Ëñ¨„ÇíÁî®„ÅÑ„Çã„Ç±„Éº„Çπ„ÅåÂ¢ó„Åà„Å¶„ÅÑ„Çã„ÄÇ'],\n",
       "       ['„Éî„Éö„É©„Ç∏„É≥', '1,2-„Ç∏„ÇØ„É≠„É≠„Ç®„Çø„É≥„Å®„Ç¢„É≥„É¢„Éã„Ç¢„Çí„ÄÅÊ∞¥ÈÖ∏Âåñ„Éä„Éà„É™„Ç¶„É†Â≠òÂú®‰∏ã„ÅßÂèçÂøú„Åï„Åõ„Çã„ÄÇ']], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_false[pred_false.label == True][['title', 'sentence']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
