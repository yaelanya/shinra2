{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Embedding, Bidirectional, TimeDistributed, LSTM, Dense, concatenate, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Model\n",
    "from keras import metrics\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras_contrib.layers import CRF\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix ramdom seed.\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.UNK = '<UNK>'\n",
    "        self.PAD = '<PAD>'\n",
    "        self.vocab_word = {self.PAD: 0, self.UNK: 1}\n",
    "        self.vocab_char = {self.PAD: 0, self.UNK: 1}\n",
    "        self.vocab_tag = {self.PAD: 0}\n",
    "        \n",
    "    def fit(self, sentences, tags, row_sentences=None):\n",
    "        self._fit_word(sentences)\n",
    "        \n",
    "        if row_sentences:\n",
    "            self._fit_char(row_sentences)\n",
    "        else:\n",
    "            self._fit_char(sentences)\n",
    "        \n",
    "        self._fit_tag(tags)\n",
    "        \n",
    "        self.vocab_word_size = len(self.vocab_word)\n",
    "        self.vocab_char_size = len(self.vocab_char)\n",
    "        self.vocab_tag_size = len(self.vocab_tag)\n",
    "    \n",
    "    def inverse_transform_tag(self, tag_id_seq):\n",
    "        seq = []\n",
    "        inv_vocab_tag = {v: k for k, v in self.vocab_tag.items()}\n",
    "        for tag_ids in tag_id_seq:\n",
    "            tags = [inv_vocab_tag[tag_id] for tag_id in tag_ids]\n",
    "            seq.append(tags)\n",
    "\n",
    "        return seq\n",
    "    \n",
    "    def padding_word(self, word_seq):\n",
    "        return pad_sequences(word_seq, padding='post')\n",
    "    \n",
    "    def padding_char(self, char_seq):\n",
    "        char_max = max([len(max(char_seq_in_sent, key=len)) for char_seq_in_sent in char_seq])\n",
    "        pad_seq = [pad_sequences(char_seq_in_sent, maxlen=char_max, padding='post') for char_seq_in_sent in char_seq]\n",
    "        \n",
    "        # 文の長さも揃える\n",
    "        return pad_sequences(pad_seq, padding='post')\n",
    "    \n",
    "    def padding_tag(self, tag_seq):\n",
    "        return pad_sequences(tag_seq, padding='post')\n",
    "\n",
    "    def _fit_word(self, sentences):\n",
    "        for s in sentences:\n",
    "            for w in s:\n",
    "                if w in self.vocab_word:\n",
    "                    continue\n",
    "                self.vocab_word[w] = len(self.vocab_word)\n",
    "                \n",
    "    def _fit_char(self, sentences):\n",
    "        for s in sentences:\n",
    "            for w in s:\n",
    "                for c in w:\n",
    "                    if c in self.vocab_char:\n",
    "                        continue\n",
    "                    self.vocab_char[c] = len(self.vocab_char)\n",
    "                    \n",
    "    def _fit_tag(self, tag_seq):\n",
    "        for tags in tag_seq:\n",
    "            for tag in tags:\n",
    "                if tag in self.vocab_tag:\n",
    "                    continue\n",
    "                self.vocab_tag[tag] = len(self.vocab_tag)\n",
    "                \n",
    "    def transform_word(self, sentences):\n",
    "        seq = []\n",
    "        for s in sentences:\n",
    "            word_ids = [self.vocab_word.get(w, self.vocab_word[self.UNK]) for w in s]\n",
    "            seq.append(word_ids)\n",
    "            \n",
    "        return seq\n",
    "    \n",
    "    def transform_char(self, sentences):\n",
    "        seq = []\n",
    "        for s in sentences:\n",
    "            char_seq = []\n",
    "            for w in s:\n",
    "                char_ids = [self.vocab_char.get(c, self.vocab_char[self.UNK]) for c in w]\n",
    "                char_seq.append(char_ids)\n",
    "            seq.append(char_seq)\n",
    "            \n",
    "        return seq\n",
    "    \n",
    "    def transform_tag(self, tag_seq):\n",
    "        seq = []\n",
    "        for tags in tag_seq:\n",
    "            tag_ids = [self.vocab_tag[tag] for tag in tags]\n",
    "            seq.append(tag_ids)\n",
    "\n",
    "        return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(X, y, batch_size, tokenizer, shuffle=True):\n",
    "    num_batches_per_epoch = int((len(X[0]) - 1) / batch_size) + 1\n",
    "\n",
    "    def data_generator():\n",
    "        data_size = len(X[0])\n",
    "        while True:\n",
    "            # Shuffle the data at each epoch\n",
    "            if shuffle:\n",
    "                shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "                shuffled_X = [np.array(_input)[shuffle_indices] for _input in X]\n",
    "                shuffled_y = np.array(y)[shuffle_indices]\n",
    "            else:\n",
    "                shuffled_data = X\n",
    "                shuffled_labels = y\n",
    "\n",
    "            for batch_num in range(num_batches_per_epoch):\n",
    "                start_index = batch_num * batch_size\n",
    "                end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "                batch_X = [_input[start_index: end_index] for _input in shuffled_X]\n",
    "                batch_y = shuffled_y[start_index: end_index]\n",
    "                \n",
    "                batch_X[0] = tokenizer.padding_word(batch_X[0])\n",
    "                batch_X[1] = tokenizer.padding_char(batch_X[1])\n",
    "                batch_X[2] = np.array([[batch_X[2][i]] * len(x) for i, x in enumerate(batch_X[0])])\n",
    "                \n",
    "                batch_y = tokenizer.padding_tag(batch_y)\n",
    "                \n",
    "                yield batch_X, batch_y\n",
    "\n",
    "    return num_batches_per_epoch, data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col_name = {\n",
    "    'ふりがな': \"production_tag_seq\"\n",
    "    , '別称': \"another_name_tag_seq\"\n",
    "    , '用途': \"use_tag_seq\"\n",
    "    , '種類': \"type_tag_seq\"\n",
    "    , '商標名': \"trademark_tag_seq\"\n",
    "    , '特性': \"property_tag_seq\"\n",
    "    , '原材料': \"raw_material_tag_seq\"\n",
    "    , '製造方法': \"production_tag_seq\"\n",
    "    , '生成化合物': \"formation_tag_seq\"\n",
    "    , 'CAS番号': \"cas_tag_seq\"\n",
    "    , '化学式': \"chemical_formula_tag_seq\"\n",
    "    , '密度': \"density_tag_seq\"\n",
    "    , '融点': \"melting_tag_seq\"\n",
    "    , '沸点': \"boiling_tag_seq\"\n",
    "    , '示性式': \"rational_formula_tag_seq\"\n",
    "}\n",
    "\n",
    "target_headline_name = {\n",
    "    '原材料': \"cat_raw_material_headline\"\n",
    "    , '製造方法': \"cat_production_headline\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_df = pd.read_pickle(\"../data/train_IOB_repl_compound.pkl\")\n",
    "test_df = pd.read_pickle(\"../data/test_IOB_repl_compound.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MyTokenizer()\n",
    "tokenizer.fit(\n",
    "    sentences=train_df.repl_words.tolist()\n",
    "    , row_sentences=train_df.words.tolist()\n",
    "    , tags=['B', 'I', 'O']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'char_vocab_size': tokenizer.vocab_char_size\n",
    "    , 'word_vocab_size':tokenizer.vocab_word_size\n",
    "    , 'tag_size': tokenizer.vocab_tag_size\n",
    "    , 'char_emb_dim': 25\n",
    "    , 'word_emb_dim': 100\n",
    "    , 'char_lstm_units': 25\n",
    "    , 'word_lstm_units': 100\n",
    "    , 'dropout_rate': 0.5\n",
    "    , 'lstm_activation': 'tanh'\n",
    "    , 'fc_activation': 'tanh'\n",
    "    , 'fc_units': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_53 (InputLayer)           (None, None, None)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_37 (Embedding)        (None, None, None, 2 52975       input_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_54 (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_19 (TimeDistri (None, None, 50)     10200       embedding_37[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_38 (Embedding)        (None, None, 100)    1172300     input_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, None, 150)    0           time_distributed_19[0][0]        \n",
      "                                                                 embedding_38[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, None, 150)    0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_36 (Bidirectional (None, None, 200)    200800      dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_55 (InputLayer)           (None, None, 3)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, None, 203)    0           bidirectional_36[0][0]           \n",
      "                                                                 input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, None, 100)    20400       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, None, 4)      404         dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "crf_12 (CRF)                    (None, None, 4)      44          dense_24[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,457,123\n",
      "Trainable params: 1,457,123\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "char_input = Input(shape=(None, None))\n",
    "word_input = Input(shape=(None,))\n",
    "headline_input = Input(shape=(None, 3))\n",
    "\n",
    "char_emb = Embedding(input_dim=param['char_vocab_size']\n",
    "                     , output_dim=param['char_emb_dim']\n",
    "                     , mask_zero=True)(char_input)\n",
    "char_emb = TimeDistributed(Bidirectional(LSTM(units=param['char_lstm_units'], activation=param['lstm_activation'])))(char_emb)\n",
    "\n",
    "word_emb = Embedding(input_dim=param['word_vocab_size']\n",
    "                     , output_dim=param['word_emb_dim']\n",
    "                     , mask_zero=True)(word_input)\n",
    "\n",
    "feats = concatenate([char_emb, word_emb])\n",
    "\n",
    "feats = Dropout(param['dropout_rate'])(feats)\n",
    "\n",
    "feats = Bidirectional(LSTM(units=param['word_lstm_units'], return_sequences=True, activation=param['lstm_activation']))(feats)\n",
    "\n",
    "feats = concatenate([feats, headline_input])\n",
    "\n",
    "feats = Dense(param['fc_units'], activation=param['fc_activation'])(feats)\n",
    "feats = Dense(param['tag_size'])(feats)\n",
    "\n",
    "crf = CRF(param['tag_size'])\n",
    "pred = crf(feats)\n",
    "\n",
    "model = Model(inputs=[word_input, char_input, headline_input], outputs=pred)\n",
    "\n",
    "sgd = SGD(lr=0.01, clipvalue=5.) # original paper\n",
    "adam = Adam()\n",
    "\n",
    "model.compile(loss=crf.loss_function, optimizer=adam)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽出対象の属性を指定\n",
    "target_attr = \"原材料\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_onehot(tag_seq, tokenizer):\n",
    "    return np.array([np.identity(tokenizer.vocab_tag_size)[tags] for tags in tag_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_word_train = tokenizer.transform_word(train_df.repl_words.tolist())\n",
    "x_char_train = tokenizer.transform_char(train_df.words.tolist())\n",
    "x_headline_train = pd.get_dummies(train_df[target_headline_name[target_attr]]).values\n",
    "y_train = tokenizer.transform_tag(train_df[target_col_name[target_attr]].tolist())\n",
    "\n",
    "x_word_test = tokenizer.transform_word(test_df.repl_words.tolist())\n",
    "x_char_test = tokenizer.transform_char(test_df.words.tolist())\n",
    "x_headline_test = pd.get_dummies(test_df[target_headline_name[target_attr]]).values\n",
    "y_test = tokenizer.transform_tag(test_df[target_col_name[target_attr]].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "y_train = encoding_onehot(y_train, tokenizer)\n",
    "y_test = encoding_onehot(y_test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps, train_batches = batch_iter([x_word_train, x_char_train, x_headline_train], y_train, batch_size, tokenizer)\n",
    "valid_steps, valid_batches = batch_iter([x_word_test, x_char_test, x_headline_test], y_test, batch_size, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "233/233 [==============================] - 143s 614ms/step - loss: 4.3660\n",
      "Epoch 2/50\n",
      "233/233 [==============================] - 150s 644ms/step - loss: 4.3619\n",
      "Epoch 3/50\n",
      " 94/233 [===========>..................] - ETA: 1:34 - loss: 4.1099"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-10c5321ce14b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit_generator(train_batches, train_steps\n\u001b[1;32m      2\u001b[0m                     \u001b[0;31m#, validation_data=valid_batches, validation_steps=valid_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                     \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                    )\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.6.1/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.6.1/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.6.1/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.6.1/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.6.1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.6.1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.6.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_batches, train_steps\n",
    "                    #, validation_data=valid_batches, validation_steps=valid_batches\n",
    "                    , epochs=50\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../model/multi-crf_with_production_raw-material.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"../model/raw-material.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_x_word_test = tokenizer.padding_word(x_word_test)\n",
    "pad_x_char_test = tokenizer.padding_char(x_char_test)\n",
    "pad_y_test = [tokenizer.padding_tag(target) for target in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([pad_x_word_test, pad_x_char_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/compound_train.json\", 'r') as f:\n",
    "    raw_train = json.load(f)\n",
    "    train_dict = {str(entry['WikipediaID']): {'title': entry['Name'], 'attributes': entry['Attributes']} for entry in raw_train['entry']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [i for sub_l in l for i in sub_l]\n",
    "\n",
    "def extract_words(word_seq, tag_seq):\n",
    "    words_list = []\n",
    "    words = []\n",
    "    for word, tag in zip(word_seq, tag_seq):\n",
    "        '''\n",
    "        if ((tag == 2) and (len(phrase) == 0)) or ((tag == 3) and (len(phrase) > 0)):\n",
    "            phrase.append(word)\n",
    "        elif tag == 2 and len(phrase) > 0:\n",
    "            phrase_list.append(phrase)\n",
    "            phrase = [word]\n",
    "        '''\n",
    "        if tag == tokenizer.vocab_tag['B'] or tag == tokenizer.vocab_tag['I']:\n",
    "            words.append(word)\n",
    "        elif words:\n",
    "            words_list.append(words)\n",
    "            words = []\n",
    "\n",
    "    if words:\n",
    "        words_list.append(words)\n",
    "        \n",
    "    return words_list\n",
    "\n",
    "def extract_strings(sentence, extracted_words):\n",
    "    if extracted_words:\n",
    "        patt = extract_pattern(extracted_words)\n",
    "        return re.findall(patt, sentence)\n",
    "    return []\n",
    "\n",
    "def escape(s):\n",
    "    _s = s.replace(r'.', r'\\.')\n",
    "    _s = _s.replace(r'+', r'\\+')\n",
    "    _s = _s.replace(r'-', r'\\-')\n",
    "    _s = _s.replace(r'^', r'\\^')\n",
    "    _s = _s.replace(r'?', r'\\?')\n",
    "    _s = _s.replace(r'$', r'\\$')\n",
    "    _s = _s.replace(r'|', r'\\|')\n",
    "    _s = _s.replace(r'(', r'\\(').replace(r')', r'\\)')\n",
    "    _s = _s.replace(r'[', r'\\[').replace(r']', r'\\]')\n",
    "    _s = _s.replace(r'{', r'\\{').replace(r'}', r'\\}')\n",
    "    \n",
    "    _s = _s.replace(r'*', '\\*')\n",
    "    _s = re.sub(r'\\\\s\\\\\\*', '\\s*', _s)\n",
    "    \n",
    "    return _s\n",
    "\n",
    "def extract_pattern(chunks):\n",
    "    patt = [''.join(chunk) for chunk in chunks]\n",
    "    patt = ['\\s*'.join(list(p)) for p in patt] # 元の文に空白が入っている場合を考慮\n",
    "    patt = '|'.join([escape(p) for p in patt])\n",
    "    \n",
    "    return patt\n",
    "\n",
    "def evaluate_exact_match(result_dict):\n",
    "    annotation_size = 0\n",
    "    extracted_size = 0\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for _id, val in result_dict.items():\n",
    "        true_set = set(val['true'])\n",
    "        pred_set = set(val['predict'])\n",
    "        \n",
    "        annotation_size += len(true_set)\n",
    "        extracted_size += len(pred_set)\n",
    "        TP += len(true_set & pred_set)\n",
    "        FP += len(pred_set - true_set)\n",
    "        FN += len(true_set - pred_set)\n",
    "\n",
    "    def precision(TP, FP):\n",
    "            return TP / (TP + FP) if (TP + FP) != 0 else 0.0\n",
    "\n",
    "    def recall(TP, FN):\n",
    "        return TP / (TP + FN) if (TP + FN) != 0 else 0.0\n",
    "\n",
    "    def f1(precision, recall):\n",
    "        return 2 * precision * recall / (precision + recall) \\\n",
    "            if (precision + recall) != 0 else 0.0\n",
    "    \n",
    "    score = {\n",
    "        'annotation_size': annotation_size\n",
    "        , 'extracted_size': extracted_size\n",
    "        , 'TP': TP\n",
    "        , 'FP': FP\n",
    "        , 'FN': FN\n",
    "        , 'precision': precision(TP, FP)\n",
    "        , 'recall': recall(TP, FN)\n",
    "        , 'f1': f1(precision(TP, FP), recall(TP, FN))\n",
    "    }\n",
    "    \n",
    "    return score\n",
    "\n",
    "def onehot2id(onehot_seq):\n",
    "    return np.argmax(onehot_seq, -1)\n",
    "\n",
    "def remove_pad(tag_seq):\n",
    "    return [tags[np.where(tags > 0)[0]] for tags in tag_seq]\n",
    "\n",
    "def evaluate_seq(y_true, y_pred):\n",
    "    _y_true = onehot2id(y_true)\n",
    "    _y_true = remove_pad(_y_true)\n",
    "    _y_true = tokenizer.inverse_transform_tag(_y_true)\n",
    "\n",
    "    _y_pred = onehot2id(y_pred)\n",
    "    _y_pred = remove_pad(_y_pred)\n",
    "    _y_pred = tokenizer.inverse_transform_tag(_y_pred)\n",
    "\n",
    "    return {'precision': precision_score(_y_true, _y_pred)\n",
    "            , 'recall': recall_score(_y_true, _y_pred)\n",
    "            , 'f1': f1_score(_y_true, _y_pred)\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_attr = \"原材料\"\n",
    "attr_y_pred = y_pred[target_attr_list.index(target_attr)]\n",
    "attr_y_test = pad_y_test[target_attr_list.index(target_attr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.3338533541341654,\n",
       " 'precision': 0.3835125448028674,\n",
       " 'recall': 0.2955801104972376}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_seq(attr_y_test, attr_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tag_seq = remove_pad(onehot2id(attr_y_pred))\n",
    "\n",
    "extracted_dict = {}\n",
    "for i, (_, row) in enumerate(test_df.iterrows()):\n",
    "    extracted = extract_words(row.words, pred_tag_seq[i])\n",
    "    extracted = extract_strings(row.sentence, extracted)\n",
    "    extracted_dict[row._id] = extracted_dict.get(row._id, []) + extracted\n",
    "    \n",
    "result_dict = {}\n",
    "for _id in test_df._id.unique():\n",
    "    result_dict[_id] = \\\n",
    "    {'title': train_dict[_id]['title']\n",
    "     , 'true': train_dict[_id]['attributes'][target_attr]\n",
    "     , 'predict': list(set(extracted_dict.get(_id, [])))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1024773': {'predict': ['アルミニウム',\n",
       "   '一酸化炭素',\n",
       "   '芳香族炭化水素',\n",
       "   'フタルアルデヒド',\n",
       "   'ベンゼン',\n",
       "   'シクロヘキサン-1,4-ジオン'],\n",
       "  'title': 'ペンタセン',\n",
       "  'true': ['シクロヘキサン-1,4-ジオン',\n",
       "   'フタルアルデヒド',\n",
       "   'アルミニウムアマルガム',\n",
       "   'ペンタセンキノン',\n",
       "   '水',\n",
       "   'エチレン',\n",
       "   'テトラハロゲノベンゼン']},\n",
       " '1050477': {'predict': ['モルヒネ', '塩酸'], 'title': 'レミフェンタニル', 'true': []},\n",
       " '1067475': {'predict': ['オレゴングリーン', '塩化亜鉛', 'レソルシノール', '無水フタル酸'],\n",
       "  'title': 'フルオレセイン',\n",
       "  'true': ['レソルシノール', '塩化亜鉛', '無水フタル酸', 'スルホン']},\n",
       " '1095173': {'predict': ['メトヘモグロビン',\n",
       "   '青酸カリ',\n",
       "   '糖',\n",
       "   '炭素',\n",
       "   '亜硝酸アミル',\n",
       "   '酸素',\n",
       "   'アクリロニトリル',\n",
       "   'シアン化銅',\n",
       "   'シアン化ナトリウム',\n",
       "   'シアン化水素',\n",
       "   'Fe',\n",
       "   'チオシアン酸',\n",
       "   'シアン化カリウム'],\n",
       "  'title': 'シアン化物',\n",
       "  'true': []},\n",
       " '1140453': {'predict': [], 'title': 'ピパンペロン', 'true': []},\n",
       " '1148105': {'predict': [], 'title': 'グラニセトロン', 'true': []},\n",
       " '1193389': {'predict': ['III',\n",
       "   'ロジウム(III)',\n",
       "   '塩化水素',\n",
       "   '粉末',\n",
       "   '水酸化カリウム',\n",
       "   '水酸化',\n",
       "   '濃塩酸',\n",
       "   '和物',\n",
       "   '塩素ガス',\n",
       "   'ヘキサクロロロジウム酸(III',\n",
       "   '塩化カリウム'],\n",
       "  'title': '塩化ロジウム(III)',\n",
       "  'true': ['塩化水素',\n",
       "   'ロジウム',\n",
       "   'ヘキサクロロロジウム酸(III)カリウム',\n",
       "   '水酸化ロジウム(III)',\n",
       "   '水酸化カリウム',\n",
       "   '塩化カリウム',\n",
       "   '濃塩酸',\n",
       "   '塩化ロジウム三水和物',\n",
       "   '塩素ガス']},\n",
       " '1198019': {'predict': ['シトラール',\n",
       "   '三フッ化ホウ素',\n",
       "   'アセトン',\n",
       "   '22%',\n",
       "   'アルドール',\n",
       "   '塩基触媒',\n",
       "   'リン酸',\n",
       "   '希酸'],\n",
       "  'title': 'イオノン',\n",
       "  'true': ['プソイドイオノン',\n",
       "   '植物の精油',\n",
       "   '硫酸',\n",
       "   '三フッ化ホウ素',\n",
       "   'リン酸',\n",
       "   '希酸',\n",
       "   'シトラール',\n",
       "   'アセトン']},\n",
       " '1203950': {'predict': ['メグルミン'], 'title': 'フルニキシン', 'true': []},\n",
       " '12437': {'predict': ['酢酸',\n",
       "   'メタノール',\n",
       "   'エチレン',\n",
       "   '酸化剤',\n",
       "   '石油',\n",
       "   '水素化ナトリウム',\n",
       "   'エチレングリコール',\n",
       "   '硫酸',\n",
       "   'アセトアルデヒド'],\n",
       "  'title': 'エタノール',\n",
       "  'true': ['アルコール', 'エチレン']},\n",
       " '1273537': {'predict': ['酸塩化物', 'ヘキサメチレンジアミン'],\n",
       "  'title': '塩化アジポイル',\n",
       "  'true': ['アジピン酸']},\n",
       " '1372856': {'predict': [], 'title': 'チオ酢酸', 'true': []},\n",
       " '1383346': {'predict': [], 'title': '一酸化銀', 'true': []},\n",
       " '1454192': {'predict': [], 'title': 'テトラヒドロゾリン', 'true': []},\n",
       " '1483298': {'predict': ['塩化白金酸', '硝酸ナトリウム', '酢酸', 'アンモニア', 'アダムス'],\n",
       "  'title': 'アダムス触媒',\n",
       "  'true': ['塩化白金酸アンモニウム', '硝酸ナトリウム', '塩化白金酸']},\n",
       " '1540694': {'predict': [], 'title': '窒化ベリリウム', 'true': []},\n",
       " '1560938': {'predict': [], 'title': 'オンダンセトロン', 'true': []},\n",
       " '1563432': {'predict': ['23'],\n",
       "  'title': 'リゾホスファチジン酸',\n",
       "  'true': ['リゾホスファチジルコリン']},\n",
       " '1573835': {'predict': [], 'title': '安息香酸カルシウム', 'true': []},\n",
       " '1591322': {'predict': [],\n",
       "  'title': 'デキストラン',\n",
       "  'true': ['Leuconostoc mesenteroides が生産する高分子デキストラン', '高分子デキストラン', 'スクロース']},\n",
       " '160786': {'predict': ['ケイ皮酸', 'ベンゼン', 'メタノール', '炭酸酵素', '塩素'],\n",
       "  'title': 'スチレン',\n",
       "  'true': ['エチルベンゼン', 'ケイ皮酸脱炭酸酵素', 'ケイ皮酸']},\n",
       " '1616237': {'predict': ['グアニジン', 'ビグアニド'], 'title': 'フェンホルミン', 'true': []},\n",
       " '1625510': {'predict': ['クロロギ酸エチル', 'アントラニル酸', 'ホスゲン', '二酸化炭素'],\n",
       "  'title': 'イサト酸無水物',\n",
       "  'true': ['アントラニル酸ナトリウム', 'ホスゲン', 'アントラニル酸', 'クロロギ酸エチル', 'ベンズイソオキサゾール']},\n",
       " '1658717': {'predict': ['五フッ化ヨウ素', 'フッ素', 'ヨウ'],\n",
       "  'title': '七フッ化ヨウ素',\n",
       "  'true': ['五フッ化ヨウ素', 'フッ素']},\n",
       " '1663779': {'predict': ['ベンジル', 'アンモニア', 'ベンゾニトリル'],\n",
       "  'title': 'ベンジルアミン',\n",
       "  'true': ['ベンゾニトリル', '水素']},\n",
       " '1690387': {'predict': ['水銀'], 'title': 'シアン化水銀(II)', 'true': ['シアン', '水銀']},\n",
       " '1787749': {'predict': ['-ビスリン酸', 'ビスリン酸'],\n",
       "  'title': 'イノシトールトリスリン酸',\n",
       "  'true': ['ホスファチジルイノシトール4,5-ビスリン酸']},\n",
       " '1793432': {'predict': [], 'title': 'ヨウ化亜鉛', 'true': []},\n",
       " '1815995': {'predict': [], 'title': 'フッ化亜鉛', 'true': []},\n",
       " '1866600': {'predict': ['水素',\n",
       "   '窒素',\n",
       "   '亜硝酸エステル',\n",
       "   'メチルエチルケトン',\n",
       "   'ヒドロキシルアミン硫酸ナトリウム',\n",
       "   'ジケトン',\n",
       "   'ベンジル'],\n",
       "  'title': 'ジメチルグリオキシム',\n",
       "  'true': ['オキシム', 'ヒドロキシルアミン硫酸ナトリウム', 'メチルエチルケトン', '亜硝酸エステル']},\n",
       " '189601': {'predict': [],\n",
       "  'title': 'シガトキシン',\n",
       "  'true': ['藻類', '有毒渦鞭毛藻', 'ポリケチド']},\n",
       " '1905810': {'predict': ['二酸化炭素', 'CO 3', 'CO3', 'アンモニア水', '四水和物', '水酸化ベリリウム'],\n",
       "  'title': '炭酸ベリリウム',\n",
       "  'true': ['二酸化炭素', '水', '水酸化ベリリウム']},\n",
       " '1905814': {'predict': ['アンモニア水'],\n",
       "  'title': '水酸化ベリリウム',\n",
       "  'true': ['水酸化ナトリウム', 'ベリリウム塩', 'アンモニア 水']},\n",
       " '1932135': {'predict': ['ピペリジン', '炭素'], 'title': 'トロパン', 'true': ['オルニチン']},\n",
       " '1936318': {'predict': ['メタリジウム'],\n",
       "  'title': 'スワインソニン',\n",
       "  'true': ['菌',\n",
       "   'メタリジウム',\n",
       "   'Astragalus lentiginosus',\n",
       "   'Swainosona canescens (Benth.) A Lee',\n",
       "   'Rhizoctonia leguminicola',\n",
       "   '被子植物']},\n",
       " '1939275': {'predict': [], 'title': 'パントイン酸', 'true': []},\n",
       " '19566': {'predict': ['メタン',\n",
       "   '空気',\n",
       "   '酸',\n",
       "   'アミグダリン',\n",
       "   'ガス',\n",
       "   'アクリロニトリル',\n",
       "   'シアン化ナトリウム',\n",
       "   '金属イオン',\n",
       "   'アンモニア',\n",
       "   'シアン化物',\n",
       "   '硫酸',\n",
       "   'エムルシン'],\n",
       "  'title': 'シアン化水素',\n",
       "  'true': ['空気', 'アンモニア', 'メタン', 'シアン化ナトリウム', '酸']},\n",
       " '1977270': {'predict': ['フッ素', 'アンチモン'],\n",
       "  'title': '三フッ化アンチモン',\n",
       "  'true': ['三酸化アンチモン', 'フッ化水素']},\n",
       " '1980911': {'predict': ['まず 1,3-ジエン', 'ピロール', 'ジクロロホスフィン', 'トリフェニルホスフィン'],\n",
       "  'title': 'ホスホール',\n",
       "  'true': []},\n",
       " '2061207': {'predict': [], 'title': 'ヘキサフルオロプロペン', 'true': []},\n",
       " '2080116': {'predict': [], 'title': 'カナジン', 'true': []},\n",
       " '2137257': {'predict': ['チオ硫酸ナトリウム',\n",
       "   '亜硝酸アミル',\n",
       "   '鉄イオン',\n",
       "   '酸素',\n",
       "   'グルタチオン',\n",
       "   'アスコルビン酸'],\n",
       "  'title': 'メトヘモグロビン',\n",
       "  'true': []},\n",
       " '2140608': {'predict': [], 'title': 'プロトカテク酸', 'true': []},\n",
       " '2153576': {'predict': [], 'title': 'リラグルチド', 'true': []},\n",
       " '2170531': {'predict': [], 'title': 'スルファメトキサゾール', 'true': []},\n",
       " '217088': {'predict': [], 'title': 'エナラプリル', 'true': []},\n",
       " '2190946': {'predict': [], 'title': 'フェニルアセトン', 'true': []},\n",
       " '2211690': {'predict': [], 'title': 'パクロブトラゾール', 'true': []},\n",
       " '2234076': {'predict': ['アンモニア'],\n",
       "  'title': 'イソブチルアミン',\n",
       "  'true': ['水素', 'イソプロパノール', 'アンモニア']},\n",
       " '2312494': {'predict': [], 'title': 'リンモリブデン酸', 'true': []},\n",
       " '2334030': {'predict': ['en', 'フィリピンIII', 'フィリピン', '放線菌'],\n",
       "  'title': 'フィリピン (化合物)',\n",
       "  'true': ['放線菌Streptomyces filipinensisの菌糸体および培養濾液']},\n",
       " '2346795': {'predict': ['オクタン溶液', '金属', 'CO', 'ジアゾメタン'],\n",
       "  'title': 'デカカルボニルジヒドリド三オスミウム',\n",
       "  'true': []},\n",
       " '2488348': {'predict': [], 'title': 'オルトフタルアルデヒド', 'true': []},\n",
       " '248891': {'predict': ['天然'], 'title': 'マイトトキシン', 'true': ['ポリエーテル', '硫酸']},\n",
       " '2569592': {'predict': ['ブロモエタン', '塩化銀', '臭素'],\n",
       "  'title': 'エドロホニウム',\n",
       "  'true': ['塩化銀', 'エドロホニウム臭化物', 'ブロモエタン', '3-ジメチルアミノフェノール']},\n",
       " '2614499': {'predict': [], 'title': '2-シクロプロペンカルボン酸', 'true': []},\n",
       " '2727655': {'predict': [], 'title': 'リン化コバルト(II)', 'true': []},\n",
       " '2790003': {'predict': ['アジリジン', '塩化チオホスホリル'],\n",
       "  'title': 'チオテパ',\n",
       "  'true': ['アジリジン', '塩化チオホスホリル']},\n",
       " '2795973': {'predict': ['ゲラニオール', 'nardus'],\n",
       "  'title': 'シトロネロール',\n",
       "  'true': ['ゲラニオール']},\n",
       " '2806294': {'predict': ['パクリタキセル'], 'title': 'パチョロール', 'true': []},\n",
       " '2807214': {'predict': [], 'title': 'ホズルシン', 'true': []},\n",
       " '2823300': {'predict': [], 'title': 'ベラトリジン', 'true': []},\n",
       " '293373': {'predict': [], 'title': 'フェンタニル', 'true': []},\n",
       " '29891': {'predict': ['オレフィン', '酸', 'アルコール'],\n",
       "  'title': 'エーテル (化学)',\n",
       "  'true': ['オレフィン', '求電子剤', '有機ハロゲン化合物', 'アルコキシド', 'アルコール']},\n",
       " '2996837': {'predict': ['メルドラム酸', '無水マレイン酸'],\n",
       "  'title': 'エチレンテトラカルボン酸二無水物',\n",
       "  'true': ['エチレンテトラカルボン酸', 'メルドラム酸']},\n",
       " '3020464': {'predict': [], 'title': 'オクテン', 'true': []},\n",
       " '305316': {'predict': ['炭酸水素カルシウム', '希硫酸', '硫酸'],\n",
       "  'title': '硫酸カルシウム',\n",
       "  'true': ['カルシウム塩の水溶液', '希硫酸', '硫酸塩水溶液', '水酸化カルシウム', '硫酸']},\n",
       " '31121': {'predict': ['局', 'フロリダ', 'エイプリルフール', '水'],\n",
       "  'title': 'DHMO',\n",
       "  'true': []},\n",
       " '3273180': {'predict': [], 'title': 'フルフェナム酸', 'true': []},\n",
       " '3283637': {'predict': [], 'title': 'クリオキノール', 'true': []},\n",
       " '3342427': {'predict': ['ピリジン', 'ケリドン酸', 'アンモニア'],\n",
       "  'title': 'ケリダム酸',\n",
       "  'true': ['4-ピロン-2,6-ジカルボン酸', 'アンモニア', 'ケリドン酸']},\n",
       " '3352098': {'predict': ['無水フッ化水素酸',\n",
       "   '四塩化炭素',\n",
       "   '塩化ウラン(V)',\n",
       "   '酸化ウラン(VI)',\n",
       "   '塩化ウラン(IV)',\n",
       "   '塩素',\n",
       "   'HF'],\n",
       "  'title': '塩化ウラン(VI)',\n",
       "  'true': ['酸化ウラン(VI)', '塩素', '四塩化炭素', 'UO3']},\n",
       " '3419435': {'predict': [], 'title': 'アゼルニジピン', 'true': []},\n",
       " '3448226': {'predict': [], 'title': 'マンノサミン', 'true': []},\n",
       " '3460340': {'predict': [], 'title': 'ネビラピン', 'true': []},\n",
       " '3463386': {'predict': ['硫黄', '炭水化物', 'ヨウ素'],\n",
       "  'title': 'トリフルオロメタンスルホン酸銀',\n",
       "  'true': ['トリフラート', '銀']},\n",
       " '3472884': {'predict': ['MOCVD'], 'title': 'REBCO', 'true': []},\n",
       " '3474570': {'predict': [],\n",
       "  'title': 'オルニチンα‐ケトグルタル酸',\n",
       "  'true': ['オルニチン', 'α-ケトグルタル酸']},\n",
       " '3483975': {'predict': ['ゲルマニウム', '塩素'],\n",
       "  'title': '二塩化ゲルマニウム',\n",
       "  'true': ['四塩化ゲルマニウム', 'クロロゲルマン', 'GeCl4', 'ゲルマニウム金属']},\n",
       " '3519068': {'predict': ['ジイソプロピルアミン'],\n",
       "  'title': 'トリイソプロピルアミン',\n",
       "  'true': ['ジイソプロピルアミン']},\n",
       " '3526170': {'predict': [], 'title': 'リン酸三カルシウム', 'true': ['リン酸', 'カルシウム']},\n",
       " '3529078': {'predict': [], 'title': 'ビベンジル', 'true': ['フェニル基', 'エタン']},\n",
       " '3560674': {'predict': [], 'title': '2-モルホリノエタノール', 'true': []},\n",
       " '3570913': {'predict': ['メタン', 'ヨードメタン'],\n",
       "  'title': 'メチルホスホン酸ジメチル',\n",
       "  'true': ['亜リン酸トリメチル', 'ハロメタン', 'ヨードメタン']},\n",
       " '3683375': {'predict': [],\n",
       "  'title': 'ミトコンドリアフェリチン',\n",
       "  'true': ['βシート', 'ヘリックス', 'αヘリックス']},\n",
       " '41685': {'predict': ['カルボキシル基', 'グルタミン酸'], 'title': 'Γ-アミノ酪酸', 'true': []},\n",
       " '497499': {'predict': ['メチルアミン'],\n",
       "  'title': 'N-メチルピロリドン',\n",
       "  'true': ['γ-ブチロラクトン', 'メチルアミン']},\n",
       " '514541': {'predict': ['水銀(I)塩の水溶液', '水銀'], 'title': '酸化水銀', 'true': []},\n",
       " '520951': {'predict': ['水酸化ナトリウム', 'アンモニア'],\n",
       "  'title': 'ピペラジン',\n",
       "  'true': ['水酸化ナトリウム', '1,2-ジクロロエタン', 'アンモニア']},\n",
       " '523020': {'predict': ['水素化ホウ素ナトリウム', 'ヨウ化メチル', 'α-'],\n",
       "  'title': 'チオアミド',\n",
       "  'true': ['アミド', '五硫化二リン', '硫黄', 'P2S5', 'ローソン試薬']},\n",
       " '616186': {'predict': ['ビタミンC', 'アミグダリン'], 'title': 'アミグダリン', 'true': []},\n",
       " '62444': {'predict': ['二酸化硫黄', 'アントラニル酸', '亜硝酸', '糖', '塩素', 'アンモニア'],\n",
       "  'title': 'サッカリン',\n",
       "  'true': ['塩素', 'アントラニル酸', '二酸化硫黄', 'トルエン', 'アンモニア', '亜硝酸', '2-クロロトルエン']},\n",
       " '62464': {'predict': ['尿酸', 'シアン酸アンモニウム', '窒素', 'アンモニア', '水'],\n",
       "  'title': '尿素',\n",
       "  'true': ['シアン酸アンモニウム', 'アンモニア', '窒素']},\n",
       " '704021': {'predict': ['3-メトキシ-1-トリメチルシリルプロピン',\n",
       "   'マレイン酸ジエチル',\n",
       "   'コバルト',\n",
       "   '1,5-ヘキサジイン',\n",
       "   '1-（トリブチルスタンニル）プロピン',\n",
       "   'n-ブチルリチウム',\n",
       "   '-（トリメチルシリロキシ'],\n",
       "  'title': 'ロケッテン',\n",
       "  'true': ['n -ブチルリチウム',\n",
       "   '1,3-ブタジエン',\n",
       "   'シクロブタベンゼン誘導体',\n",
       "   'マレイン酸ジエチル',\n",
       "   '3-（トリメチルシリロキシ）-1-（トリブチルスタンニル）プロピン',\n",
       "   '1,5-ヘキサジイン',\n",
       "   '3-メトキシ-1-トリメチルシリルプロピン',\n",
       "   'コバルト錯体']},\n",
       " '778300': {'predict': [], 'title': 'Ε-アミノカプロン酸', 'true': []},\n",
       " '884244': {'predict': ['二クロム酸'], 'title': 'クロム酸', 'true': []},\n",
       " '954930': {'predict': [], 'title': 'ククルビタシン', 'true': []},\n",
       " '969196': {'predict': ['天然'], 'title': 'グルコノラクトン', 'true': ['グルコース']}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FN': 91,\n",
       " 'FP': 135,\n",
       " 'TP': 69,\n",
       " 'annotation_size': 160,\n",
       " 'extracted_size': 204,\n",
       " 'f1': 0.3791208791208791,\n",
       " 'precision': 0.3382352941176471,\n",
       " 'recall': 0.43125}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_exact_match(result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抽出結果をjsonファイルに出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_filename = \"../output/raw-material_with_repl-compounds.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(result_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(result_dict, f, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
